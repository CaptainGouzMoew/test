{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2b4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import global_settings\n",
    "importlib.reload(global_settings)\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03fae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f389292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8632db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data/tmp\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data/tmp2\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/output\n"
     ]
    }
   ],
   "source": [
    "# Define working folder\n",
    "\n",
    "setts = global_settings.Settings()\n",
    "\n",
    "root_folder = setts.root_folder\n",
    "tmp1_folder = setts.tmp1_folder\n",
    "tmp2_folder = setts.tmp2_folder\n",
    "output_folder = setts.output_folder\n",
    "\n",
    "# tmp1_folder = root_folder + \"/data/tmp\"\n",
    "# tmp2_folder = root_folder + \"/data/tmp2\"\n",
    "# input_folder = root_folder + \"/input\"\n",
    "# output_folder = root_folder + \"/output\"\n",
    "\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "    \n",
    "year_limit = setts.year_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a25288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_all(numbers, target):\n",
    "    left = 0\n",
    "    right = len(numbers) - 1\n",
    "    indices = []\n",
    "\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "\n",
    "        # Check if the target is found at the middle position\n",
    "        if numbers[mid] == target:\n",
    "            # Add the index to the list of indices\n",
    "            indices.append(mid)\n",
    "\n",
    "            # Check the left side for more occurrences of the target\n",
    "            left_ptr = mid - 1\n",
    "            while left_ptr >= 0 and numbers[left_ptr] == target:\n",
    "                indices.append(left_ptr)\n",
    "                left_ptr -= 1\n",
    "\n",
    "            # Check the right side for more occurrences of the target\n",
    "            right_ptr = mid + 1\n",
    "            while right_ptr < len(numbers) and numbers[right_ptr] == target:\n",
    "                indices.append(right_ptr)\n",
    "                right_ptr += 1\n",
    "\n",
    "            return indices\n",
    "\n",
    "        # If the target is smaller, ignore the right half\n",
    "        elif numbers[mid] > target:\n",
    "            right = mid - 1\n",
    "\n",
    "        # If the target is greater, ignore the left half\n",
    "        else:\n",
    "            left = mid + 1\n",
    "\n",
    "    # Target not found\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75543d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_id_service(id, df_file, df_final, uid_list):\n",
    "    df_id = df_file[df_file['UID'] == id] \n",
    "    non_df_id = df_file[df_file['UID'] != id] \n",
    "#     locations = binary_search_all(uid_list, id)\n",
    "#     df_id = df_file.loc[locations]\n",
    "#     non_df_id = df_file.drop(locations)\n",
    "    \n",
    "    if len(df_id) > 0:\n",
    "        #df_id = df_id[['UID','DOC_DATE','JOB_TYPE_DESCRIPTION', 'DEALER_CODE']]\n",
    "        df_id = df_id.dropna(subset=['Event_date'])\n",
    "        df_id['Event_date'] = df_id['Event_date'].astype(str).apply(lambda x: x[4:6]+'/'+x[6:8]+'/'+x[0:4])\n",
    "        df_id['Event_date'] = df_id['Event_date'].astype(str).apply(\n",
    "            lambda x: datetime.strptime(x, '%m/%d/%Y').strftime('%m/%d/%Y'))\n",
    "        df_id = df_id.dropna(subset=['Action'])\n",
    "        df_id = df_id.drop_duplicates()\n",
    "    df_final = pd.concat([df_final, df_id], ignore_index=True)\n",
    "    return df_final, non_df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d424cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_3052\\1706583049.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  service = pd.read_csv(root_folder + '/data/service_data.csv')[['VIN','DOC_DATE','JOB_TYPE_DESCRIPTION', 'DEALER_CODE']]\n",
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_3052\\1706583049.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')[['VIN', 'UID']]\n"
     ]
    }
   ],
   "source": [
    "# MERGE SERVICE + SALE\n",
    "\n",
    "service = pd.read_csv(root_folder + '/data/service_data.csv')[['VIN','DOC_DATE','JOB_TYPE_DESCRIPTION', 'DEALER_CODE']]\n",
    "sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')[['VIN', 'UID']]\n",
    "\n",
    "cb = pd.merge(sale, right=service, how='left', left_on= 'VIN',right_on='VIN')\n",
    "cb_og = cb[['UID','DOC_DATE','JOB_TYPE_DESCRIPTION', 'DEALER_CODE']]\n",
    "del sale, service\n",
    "#find_id_service(num, id, self.service, df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd1ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UID', 'Event_date', 'Action', 'DLR'], dtype='object')\n",
      "363322978 0 14179511\n",
      "772094353 0 13586135\n",
      "898888931 0 12924663\n",
      "903950176 0 11926604\n",
      "906688319 0 11106440\n",
      "909757040 0 10007918\n",
      "913072324 0 9287285\n",
      "914376954 0 8411666\n",
      "918055018 0 7673175\n",
      "932613738 0 6774131\n",
      "937848033 0 5899086\n",
      "946069999 0 5043374\n",
      "964551277 0 4322357\n",
      "972590063 0 3606568\n",
      "977201037 0 2914937\n",
      "982251241 0 2207005\n",
      "984463636 0 1457728\n",
      "987867639 0 772572\n",
      "3963696976 0 33643\n",
      "            UID  Event_date                Action     DLR\n",
      "0  4.207900e+09  03/24/2022                   PDI  1060.0\n",
      "1  4.207900e+09  06/24/2022            1K Service  1060.0\n",
      "2  4.207900e+09  01/16/2023  Periodic Maintenance  1060.0\n",
      "3  4.207900e+09  03/08/2023                  Body  1060.0\n",
      "4  4.207900e+09  04/03/2023        General Repair  1060.0\n"
     ]
    }
   ],
   "source": [
    "# SERVICE\n",
    "cb = cb_og.copy()\n",
    "\n",
    "df_final = pd.DataFrame({'UID': [], 'Event_date': [], 'Action': [], 'DLR': []})\n",
    "id_list = cb['UID'].drop_duplicates().sort_values().tolist()\n",
    "\n",
    "cb = cb.rename(columns={'DOC_DATE':'Event_date','JOB_TYPE_DESCRIPTION':'Action', 'DEALER_CODE':'DLR'})\n",
    "print(cb.columns)\n",
    "\n",
    "backup_break = 10000\n",
    "i = 0\n",
    "backup_count = 1\n",
    "\n",
    "\n",
    "for id in id_list:\n",
    "    if i == backup_break:\n",
    "        df_final.to_csv(output_folder + \"/customer_action_service_backup_%s.csv\" % (str(backup_count)), index=False)\n",
    "        df_final = pd.DataFrame({'UID': [], 'Event_date': [], 'Action': [], 'DLR': []})\n",
    "        i = 0\n",
    "        backup_count += 1\n",
    "        print(id, len(df_final), len(cb))\n",
    "    else:\n",
    "        #print(id, len(df_final), len(cb))\n",
    "        df_final, cb = find_id_service(id, cb, df_final, id_list)\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "print(df_final.head())\n",
    "df_final.to_csv(output_folder + \"/customer_action_service_final.csv\", index=False)\n",
    "#del cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ed15c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_3052\\2521389138.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  service = pd.read_csv(root_folder + '/data/service_data.csv')[['VIN','DOC_DATE','JOB_TYPE_DESCRIPTION', 'DEALER_CODE']]\n",
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_3052\\2521389138.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')[['VIN', 'UID']]\n"
     ]
    }
   ],
   "source": [
    "# MERGE SERVICE + SALE\n",
    "\n",
    "service = pd.read_csv(root_folder + '/data/service_data.csv')[['VIN','DOC_DATE','JOB_TYPE_DESCRIPTION', 'DEALER_CODE']]\n",
    "sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')[['VIN', 'UID']]\n",
    "\n",
    "cb = pd.merge(sale, right=service, how='left', left_on= 'VIN',right_on='VIN')\n",
    "del sale, service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0af68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cb.rename(columns={'DOC_DATE':'Event_date','JOB_TYPE_DESCRIPTION':'Action', 'DEALER_CODE':'DLR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7190b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_3052\\957128561.py:21: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cb = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190535\n",
      "363322978 0 180731\n",
      "772094353 0 170722\n",
      "898888931 0 160709\n",
      "903950176 0 150701\n",
      "906688319 0 140695\n",
      "909757040 0 130688\n",
      "913072324 0 120681\n",
      "914376954 0 110673\n",
      "918055018 0 100664\n",
      "932613738 0 90662\n",
      "937848033 0 80651\n",
      "946069999 0 70635\n",
      "964551277 0 60622\n",
      "972590063 0 50612\n",
      "977201037 0 40602\n",
      "982251241 0 30583\n",
      "984463636 0 20557\n",
      "987867639 0 10549\n",
      "3963696976 0 536\n",
      "            UID  Event_date              Action     DLR\n",
      "0  4.207900e+09  03/23/2022          Buy CR-V G  1060.0\n",
      "1  4.217900e+09  04/28/2022     Buy BRIO RS OP1  2070.0\n",
      "2  4.408401e+09  04/28/2022          Buy CR-V L  2120.0\n",
      "3  5.113215e+09  03/24/2008  Buy Civic 1.8L 5MT  2010.0\n",
      "4  5.113655e+09  03/19/2008  Buy Civic 2.0L 5AT  2010.0\n"
     ]
    }
   ],
   "source": [
    "def find_id_sale(id, df_file, df_final, uid_list):\n",
    "    df_id = df_file[df_file['UID'] == id]\n",
    "    df_id_rev = df_file[df_file['UID'] != id]\n",
    "    \n",
    "#     locations = binary_search_all(uid_list, id)\n",
    "#     df_id = df_file.loc[locations]\n",
    "#     df_id_rev = df_file.drop(locations)\n",
    "    \n",
    "    if len(df_id) > 0:\n",
    "        df_id = df_id.rename(columns={'WARRANTY_START_DATE':'Event_date','MODEL_TEXT_1':'Action', 'DEALER_CODE':'DLR'})\n",
    "        df_id['Event_date'] = df_id['Event_date'].astype(str).str.replace('-', '').apply(lambda x: x[4:6]+'/'+x[6:8]+'/'+x[0:4])\n",
    "        df_id['Event_date'] = df_id['Event_date'].astype(str).apply(\n",
    "            lambda x: datetime.strptime(x, '%m/%d/%Y').strftime('%m/%d/%Y'))\n",
    "        df_id['Action'] = df_id['Action'].apply(lambda x: 'Buy '+x)\n",
    "    df_final = pd.concat([df_final, df_id], ignore_index=True)\n",
    "    return df_final, df_id_rev\n",
    "\n",
    "df_final = pd.DataFrame({'UID': [], 'Event_date': [], 'Action': [], 'DLR': []})\n",
    "id_list = cb['UID'].drop_duplicates().sort_values().tolist()\n",
    "\n",
    "cb = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')\n",
    "cb = cb[['UID','WARRANTY_START_DATE','MODEL_TEXT_1', 'DEALER_CODE']]\n",
    "cb = cb.sort_values(by=['UID'])\n",
    "backup_break = 10000\n",
    "backup_count = 1\n",
    "i = 0\n",
    "\n",
    "print(len(id_list))\n",
    "\n",
    "for id in sorted(id_list):\n",
    "    if i == backup_break:\n",
    "        df_final.to_csv(output_folder + \"/customer_action_sale_backup_%s.csv\" % (str(backup_count)), index=False)\n",
    "        df_final = pd.DataFrame({'UID': [], 'Event_date': [], 'Action': [], 'DLR': []})\n",
    "        i = 0\n",
    "        backup_count += 1\n",
    "        print(id, len(df_final), len(cb))\n",
    "    else:\n",
    "        #print(id, len(df_final), len(cb))\n",
    "        df_final, cb = find_id_sale(id, cb, df_final, id_list)\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "df_final = df_final.drop_duplicates()\n",
    "df_final.to_csv(output_folder + \"/customer_action_sale_final.csv\", index=False)\n",
    "print(df_final.head())\n",
    "del cb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
