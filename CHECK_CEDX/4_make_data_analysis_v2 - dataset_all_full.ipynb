{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713a7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import global_settings\n",
    "importlib.reload(global_settings)\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb44ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data/tmp\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data/tmp2\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/output\n"
     ]
    }
   ],
   "source": [
    "# Define working folder\n",
    "\n",
    "setts = global_settings.Settings()\n",
    "\n",
    "root_folder = setts.root_folder\n",
    "tmp1_folder = setts.tmp1_folder\n",
    "tmp2_folder = setts.tmp2_folder\n",
    "output_folder = setts.output_folder\n",
    "\n",
    "# tmp1_folder = root_folder + \"/data/tmp\"\n",
    "# tmp2_folder = root_folder + \"/data/tmp2\"\n",
    "# input_folder = root_folder + \"/input\"\n",
    "# output_folder = root_folder + \"/output\"\n",
    "\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "    \n",
    "year_limit = setts.year_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405ac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUA FILE SERVICE TRUOC KHI CHAY CODE\n",
    "# service = pd.read_csv(root_folder + '/data/service_data.csv')\n",
    "# service['DOC_DATE'] = service['DOC_DATE'].astype(str).str.replace('-', '')\n",
    "# service.to_csv(root_folder + '/data/service_data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28349a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24448\\2219950670.py:2: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  service = pd.read_csv(root_folder + '/data/service_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read processed service data from code 1\n",
    "service = pd.read_csv(root_folder + '/data/service_data.csv')\n",
    "service['DOC_DATE'] = pd.to_datetime(service['DOC_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service = service[(service['DOC_DATE'] <= setts.month_last_dt)]\n",
    "\n",
    "# service['DROP_OFF_DATE'] = pd.to_datetime(service['DROP_OFF_DATE'], format='%Y%m%d', errors='coerce')\n",
    "# service['PICK_UP_DATE'] = pd.to_datetime(service['PICK_UP_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['DOC_year'] = service['DOC_DATE'].dt.year.fillna(0)\n",
    "service['GROSS_VALUE'] = service['GROSS_VALUE'].apply(lambda x: 0 if x < 0 else float(x))\n",
    "service = service[(service['DOC_year'] > 2015) & (service['DOC_year'] <= year_limit)]\n",
    "#service = service.drop(['customer_index', 'Cust_group'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7e9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24448\\3241315745.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read processed sales data from code 2\n",
    "sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')\n",
    "sale['MODEL'] = sale['MODEL_TEXT_1'].str.split(' ').str[0]\n",
    "sale = sale.drop('MODEL_TEXT_1', axis=1)\n",
    "sale['WARRANTY_START_DATE'] = pd.to_datetime(sale['WARRANTY_START_DATE'], format='%Y-%m-%d')\n",
    "sale['START_year'] = sale['WARRANTY_START_DATE'].dt.year\n",
    "sale = sale[(sale['START_year'] > 2015) & (sale['START_year'] <= year_limit)]\n",
    "# sale = sale.drop(['DEALER_CODE', 'customer_index', 'Cust_group'], axis=1)\n",
    "sale = sale.drop(['DEALER_CODE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7aad1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_NUMBER</th>\n",
       "      <th>DEALER_CODE</th>\n",
       "      <th>CUSTOMER_CODE</th>\n",
       "      <th>VIN</th>\n",
       "      <th>DOC_DATE</th>\n",
       "      <th>DROP_OFF_DATE</th>\n",
       "      <th>PICK_UP_DATE</th>\n",
       "      <th>COUNTER_READING</th>\n",
       "      <th>COUNTER_UNIT</th>\n",
       "      <th>PART_NO</th>\n",
       "      <th>...</th>\n",
       "      <th>SALE_UNIT</th>\n",
       "      <th>NET_VALUE</th>\n",
       "      <th>GROSS_VALUE</th>\n",
       "      <th>CUSTOMER_ADVISER</th>\n",
       "      <th>NAME_OF_CUSTOMER_ADVISER</th>\n",
       "      <th>JOB</th>\n",
       "      <th>JOB_TYPE</th>\n",
       "      <th>JOB_TYPE_DESCRIPTION</th>\n",
       "      <th>DESCRIPTION_ONE</th>\n",
       "      <th>DOC_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>778693</th>\n",
       "      <td>3200071114</td>\n",
       "      <td>2020</td>\n",
       "      <td>2000080169</td>\n",
       "      <td>RLHFD1520AY902388</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>20160101202838</td>\n",
       "      <td>45000</td>\n",
       "      <td>KM</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20205002</td>\n",
       "      <td>Nguyễn Quốc Cường SA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Periodic Maintenance</td>\n",
       "      <td>K/T:dầu,nước,gạt mưa,đ/hòa,lốp,ăcquy,đèn</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778694</th>\n",
       "      <td>3200071114</td>\n",
       "      <td>2020</td>\n",
       "      <td>2000080169</td>\n",
       "      <td>RLHFD1520AY902388</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>20160101202838</td>\n",
       "      <td>45000</td>\n",
       "      <td>KM</td>\n",
       "      <td>9410914000</td>\n",
       "      <td>...</td>\n",
       "      <td>ST</td>\n",
       "      <td>3819</td>\n",
       "      <td>4201.0</td>\n",
       "      <td>20205002</td>\n",
       "      <td>Nguyễn Quốc Cường SA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Periodic Maintenance</td>\n",
       "      <td>Manual_Parts</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778695</th>\n",
       "      <td>3200071114</td>\n",
       "      <td>2020</td>\n",
       "      <td>2000080169</td>\n",
       "      <td>RLHFD1520AY902388</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>20160101202838</td>\n",
       "      <td>45000</td>\n",
       "      <td>KM</td>\n",
       "      <td>08233P99F6NV1</td>\n",
       "      <td>...</td>\n",
       "      <td>ST</td>\n",
       "      <td>408120</td>\n",
       "      <td>448932.0</td>\n",
       "      <td>20205002</td>\n",
       "      <td>Nguyễn Quốc Cường SA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Periodic Maintenance</td>\n",
       "      <td>Manual_Parts</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778696</th>\n",
       "      <td>3200071114</td>\n",
       "      <td>2020</td>\n",
       "      <td>2000080169</td>\n",
       "      <td>RLHFD1520AY902388</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>20160101202838</td>\n",
       "      <td>45000</td>\n",
       "      <td>KM</td>\n",
       "      <td>X1ENGINE66</td>\n",
       "      <td>...</td>\n",
       "      <td>ST</td>\n",
       "      <td>256300</td>\n",
       "      <td>281930.0</td>\n",
       "      <td>20205002</td>\n",
       "      <td>Nguyễn Quốc Cường SA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Periodic Maintenance</td>\n",
       "      <td>Manual_Parts</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778697</th>\n",
       "      <td>3200071114</td>\n",
       "      <td>2020</td>\n",
       "      <td>2000080169</td>\n",
       "      <td>RLHFD1520AY902388</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>20160101202838</td>\n",
       "      <td>45000</td>\n",
       "      <td>KM</td>\n",
       "      <td>X1PETROL68</td>\n",
       "      <td>...</td>\n",
       "      <td>ST</td>\n",
       "      <td>246400</td>\n",
       "      <td>271040.0</td>\n",
       "      <td>20205002</td>\n",
       "      <td>Nguyễn Quốc Cường SA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Periodic Maintenance</td>\n",
       "      <td>Manual_Parts</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154508</th>\n",
       "      <td>3203800854</td>\n",
       "      <td>1040</td>\n",
       "      <td>2000319110</td>\n",
       "      <td>RLHRS3822PY000179</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>20240430112300</td>\n",
       "      <td>3</td>\n",
       "      <td>KM</td>\n",
       "      <td>KIỂM TRA PDI</td>\n",
       "      <td>...</td>\n",
       "      <td>STD</td>\n",
       "      <td>240000</td>\n",
       "      <td>259200.0</td>\n",
       "      <td>10405061</td>\n",
       "      <td>Bùi Hải Nam</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>PDI</td>\n",
       "      <td>Service</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154509</th>\n",
       "      <td>3203800831</td>\n",
       "      <td>1040</td>\n",
       "      <td>2000319100</td>\n",
       "      <td>RLHRS3821PY000156</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>20240430112300</td>\n",
       "      <td>3</td>\n",
       "      <td>KM</td>\n",
       "      <td>KIỂM TRA PDI</td>\n",
       "      <td>...</td>\n",
       "      <td>STD</td>\n",
       "      <td>240000</td>\n",
       "      <td>259200.0</td>\n",
       "      <td>10405061</td>\n",
       "      <td>Bùi Hải Nam</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>PDI</td>\n",
       "      <td>Service</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154510</th>\n",
       "      <td>3203800763</td>\n",
       "      <td>1040</td>\n",
       "      <td>2000317024</td>\n",
       "      <td>RLHRS3844PY001948</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>20240430051100</td>\n",
       "      <td>3</td>\n",
       "      <td>KM</td>\n",
       "      <td>KIỂM TRA PDI</td>\n",
       "      <td>...</td>\n",
       "      <td>STD</td>\n",
       "      <td>240000</td>\n",
       "      <td>259200.0</td>\n",
       "      <td>10405061</td>\n",
       "      <td>Bùi Hải Nam</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>PDI</td>\n",
       "      <td>Service</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154511</th>\n",
       "      <td>3203800772</td>\n",
       "      <td>2110</td>\n",
       "      <td>2000319087</td>\n",
       "      <td>MRHRV3860RT081340</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>20240430020000</td>\n",
       "      <td>20240505010000</td>\n",
       "      <td>3</td>\n",
       "      <td>KM</td>\n",
       "      <td>PDI</td>\n",
       "      <td>...</td>\n",
       "      <td>STD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21105017</td>\n",
       "      <td>TRẦN CÔNG DUY SA</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>PDI</td>\n",
       "      <td>PDI</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154512</th>\n",
       "      <td>3203800874</td>\n",
       "      <td>1040</td>\n",
       "      <td>2000317024</td>\n",
       "      <td>RLHRS3845PY002140</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>20240430112300</td>\n",
       "      <td>3</td>\n",
       "      <td>KM</td>\n",
       "      <td>KIỂM TRA PDI</td>\n",
       "      <td>...</td>\n",
       "      <td>STD</td>\n",
       "      <td>240000</td>\n",
       "      <td>259200.0</td>\n",
       "      <td>10405061</td>\n",
       "      <td>Bùi Hải Nam</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>PDI</td>\n",
       "      <td>Service</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18375820 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORDER_NUMBER  DEALER_CODE  CUSTOMER_CODE                VIN  \\\n",
       "778693      3200071114         2020     2000080169  RLHFD1520AY902388   \n",
       "778694      3200071114         2020     2000080169  RLHFD1520AY902388   \n",
       "778695      3200071114         2020     2000080169  RLHFD1520AY902388   \n",
       "778696      3200071114         2020     2000080169  RLHFD1520AY902388   \n",
       "778697      3200071114         2020     2000080169  RLHFD1520AY902388   \n",
       "...                ...          ...            ...                ...   \n",
       "19154508    3203800854         1040     2000319110  RLHRS3822PY000179   \n",
       "19154509    3203800831         1040     2000319100  RLHRS3821PY000156   \n",
       "19154510    3203800763         1040     2000317024  RLHRS3844PY001948   \n",
       "19154511    3203800772         2110     2000319087  MRHRV3860RT081340   \n",
       "19154512    3203800874         1040     2000317024  RLHRS3845PY002140   \n",
       "\n",
       "           DOC_DATE   DROP_OFF_DATE    PICK_UP_DATE  COUNTER_READING  \\\n",
       "778693   2016-01-02               0  20160101202838            45000   \n",
       "778694   2016-01-02               0  20160101202838            45000   \n",
       "778695   2016-01-02               0  20160101202838            45000   \n",
       "778696   2016-01-02               0  20160101202838            45000   \n",
       "778697   2016-01-02               0  20160101202838            45000   \n",
       "...             ...             ...             ...              ...   \n",
       "19154508 2024-04-30               0  20240430112300                3   \n",
       "19154509 2024-04-30               0  20240430112300                3   \n",
       "19154510 2024-04-30               0  20240430051100                3   \n",
       "19154511 2024-04-30  20240430020000  20240505010000                3   \n",
       "19154512 2024-04-30               0  20240430112300                3   \n",
       "\n",
       "         COUNTER_UNIT        PART_NO  ...  SALE_UNIT NET_VALUE  GROSS_VALUE  \\\n",
       "778693             KM                 ...                    0          0.0   \n",
       "778694             KM     9410914000  ...         ST      3819       4201.0   \n",
       "778695             KM  08233P99F6NV1  ...         ST    408120     448932.0   \n",
       "778696             KM     X1ENGINE66  ...         ST    256300     281930.0   \n",
       "778697             KM     X1PETROL68  ...         ST    246400     271040.0   \n",
       "...               ...            ...  ...        ...       ...          ...   \n",
       "19154508           KM   KIỂM TRA PDI  ...        STD    240000     259200.0   \n",
       "19154509           KM   KIỂM TRA PDI  ...        STD    240000     259200.0   \n",
       "19154510           KM   KIỂM TRA PDI  ...        STD    240000     259200.0   \n",
       "19154511           KM            PDI  ...        STD         0          0.0   \n",
       "19154512           KM   KIỂM TRA PDI  ...        STD    240000     259200.0   \n",
       "\n",
       "          CUSTOMER_ADVISER  NAME_OF_CUSTOMER_ADVISER JOB  JOB_TYPE  \\\n",
       "778693            20205002      Nguyễn Quốc Cường SA   1         1   \n",
       "778694            20205002      Nguyễn Quốc Cường SA   1         1   \n",
       "778695            20205002      Nguyễn Quốc Cường SA   1         1   \n",
       "778696            20205002      Nguyễn Quốc Cường SA   1         1   \n",
       "778697            20205002      Nguyễn Quốc Cường SA   1         1   \n",
       "...                    ...                       ...  ..       ...   \n",
       "19154508          10405061               Bùi Hải Nam   1        10   \n",
       "19154509          10405061               Bùi Hải Nam   1        10   \n",
       "19154510          10405061               Bùi Hải Nam   1        10   \n",
       "19154511          21105017          TRẦN CÔNG DUY SA   1        10   \n",
       "19154512          10405061               Bùi Hải Nam   1        10   \n",
       "\n",
       "          JOB_TYPE_DESCRIPTION                           DESCRIPTION_ONE  \\\n",
       "778693    Periodic Maintenance  K/T:dầu,nước,gạt mưa,đ/hòa,lốp,ăcquy,đèn   \n",
       "778694    Periodic Maintenance                              Manual_Parts   \n",
       "778695    Periodic Maintenance                              Manual_Parts   \n",
       "778696    Periodic Maintenance                              Manual_Parts   \n",
       "778697    Periodic Maintenance                              Manual_Parts   \n",
       "...                        ...                                       ...   \n",
       "19154508                   PDI                                   Service   \n",
       "19154509                   PDI                                   Service   \n",
       "19154510                   PDI                                   Service   \n",
       "19154511                   PDI                                       PDI   \n",
       "19154512                   PDI                                   Service   \n",
       "\n",
       "         DOC_year  \n",
       "778693       2016  \n",
       "778694       2016  \n",
       "778695       2016  \n",
       "778696       2016  \n",
       "778697       2016  \n",
       "...           ...  \n",
       "19154508     2024  \n",
       "19154509     2024  \n",
       "19154510     2024  \n",
       "19154511     2024  \n",
       "19154512     2024  \n",
       "\n",
       "[18375820 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f152650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CUSTOMER_CODE_x  TITLE            CUSTOMER_NAME OCCUPATION  DISTRICT  \\\n",
      "0       2000073677    2.0  VŨ VĂN HỢP+ VŨ VĂN HỢP+        NaN  Biên Hòa   \n",
      "1       2000073677    2.0  VŨ VĂN HỢP+ VŨ VĂN HỢP+        NaN  Biên Hòa   \n",
      "2       2000073677    2.0  VŨ VĂN HỢP+ VŨ VĂN HỢP+        NaN  Biên Hòa   \n",
      "3       2000073677    2.0  VŨ VĂN HỢP+ VŨ VĂN HỢP+        NaN  Biên Hòa   \n",
      "4       2000073677    2.0  VŨ VĂN HỢP+ VŨ VĂN HỢP+        NaN  Biên Hòa   \n",
      "\n",
      "                              CUSTOMER_ADDRESS IDENTIFICATION_TYPE  \\\n",
      "0  C4/5 Kp1, P Long Bình, Tp Biên Hòa,đồng Nai              Z00001   \n",
      "1  C4/5 Kp1, P Long Bình, Tp Biên Hòa,đồng Nai              Z00001   \n",
      "2  C4/5 Kp1, P Long Bình, Tp Biên Hòa,đồng Nai              Z00001   \n",
      "3  C4/5 Kp1, P Long Bình, Tp Biên Hòa,đồng Nai              Z00001   \n",
      "4  C4/5 Kp1, P Long Bình, Tp Biên Hòa,đồng Nai              Z00001   \n",
      "\n",
      "  IDENTIFICATION_NUMBER  MARITAL_STATUS  PARTNER_CATEGORY  ... GROSS_VALUE  \\\n",
      "0            2000073677             NaN                 1  ...         0.0   \n",
      "1            2000073677             NaN                 1  ...      4201.0   \n",
      "2            2000073677             NaN                 1  ...    448932.0   \n",
      "3            2000073677             NaN                 1  ...    212080.0   \n",
      "4            2000073677             NaN                 1  ...   6739853.0   \n",
      "\n",
      "  CUSTOMER_ADVISER  NAME_OF_CUSTOMER_ADVISER  JOB  JOB_TYPE  \\\n",
      "0       30305002.0       HUỲNH DUY KHƯƠNG SA  1.0         1   \n",
      "1       30305002.0       HUỲNH DUY KHƯƠNG SA  1.0         1   \n",
      "2       30305002.0       HUỲNH DUY KHƯƠNG SA  1.0         1   \n",
      "3       30305002.0       HUỲNH DUY KHƯƠNG SA  1.0         1   \n",
      "4       30305002.0       HUỲNH DUY KHƯƠNG SA  3.0         4   \n",
      "\n",
      "   JOB_TYPE_DESCRIPTION                          DESCRIPTION_ONE DOC_year  \\\n",
      "0  Periodic Maintenance  K/T: các mức dung dịch, gạt mưa, đ/hòa,   2016.0   \n",
      "1  Periodic Maintenance                             Manual_Parts   2016.0   \n",
      "2  Periodic Maintenance                             Manual_Parts   2016.0   \n",
      "3  Periodic Maintenance                             Manual_Parts   2016.0   \n",
      "4                  Body                             Manual_Parts   2016.0   \n",
      "\n",
      "  keika bad_q  \n",
      "0   1.0     0  \n",
      "1   1.0     0  \n",
      "2   1.0     0  \n",
      "3   1.0     0  \n",
      "4   1.0     0  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Join sale and service data based on UID, left join\n",
    "#service = service.rename(columns={'VIN' : 'UID'})\n",
    "cb = pd.merge(sale, right=service, how='left', left_on= 'VIN',right_on='VIN')\n",
    "\n",
    "# Calculate number of years between DOC_DATE and WARRANTY_START_DATE\n",
    "cb['keika'] = np.ceil((cb['DOC_DATE'] - cb['WARRANTY_START_DATE']).dt.days / 365)\n",
    "\n",
    "# ?\n",
    "#cb['keika'] = cb['keika'].replace([np.inf, -np.inf], np.nan)\n",
    "cb['keika'] = cb['keika'].apply(lambda x: 1 if x == 0 else float(x))\n",
    "# Warranty = JOB_Type 07\n",
    "cb['bad_q'] = cb['JOB_TYPE'].apply(lambda x: 0 if pd.isna(x) else (1 if x == 7 or str(x) == '07' or str(x) == '7' else 0))\n",
    "cb = cb[cb['keika'] > 0]\n",
    "\n",
    "del sale, service\n",
    "print(cb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c2c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb.to_csv(output_folder + '/merged_sale_service.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9028f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID  PM2ov\n",
      "0    2      0\n",
      "1    4      1\n",
      "2    5      1\n",
      "3   12      1\n",
      "4  262      1\n"
     ]
    }
   ],
   "source": [
    "# Calculate tgt v2\n",
    "tgt = cb[cb['JOB_TYPE_DESCRIPTION'] == 'Periodic Maintenance']\n",
    "tgt = tgt.groupby('UID').agg({'DOC_DATE': lambda x: len(x.unique()), 'keika': 'max'}).reset_index()\n",
    "tgt.columns = ['UID', 'PM', 'keika_max']\n",
    "tgt['freq'] = tgt['PM'] / tgt['keika_max']\n",
    "tgt = tgt[tgt['freq'] < 11]\n",
    "tgt['PM_num'] = np.floor(tgt['freq'])\n",
    "tgt['PM2ov'] = tgt['PM_num'].apply(lambda x: 1 if x >= 2 else 0)\n",
    "tgt = tgt[['UID', 'PM2ov']]\n",
    "print(tgt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f0c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UID  CUSTOMER_ADVISER  SA_cont\n",
      "9      12        30305050.0        1\n",
      "12    559        30605003.0        1\n",
      "13    909        31605003.0        1\n",
      "24   9154        31005010.0        1\n",
      "30  36297        20205055.0        1\n"
     ]
    }
   ],
   "source": [
    "# Calculate SA_cont\n",
    "cb = cb[cb['DOC_year'] < year_limit]\n",
    "SA_cont = cb[['UID', 'DOC_DATE', 'CUSTOMER_ADVISER']].drop_duplicates()\n",
    "SA_cont['rank'] = SA_cont.groupby('UID')['DOC_DATE'].rank()\n",
    "max_rank = SA_cont.groupby('UID')['rank'].transform('max')\n",
    "SA_cont = SA_cont[SA_cont['rank'] > max_rank - 3]\n",
    "SA_cont['n'] = SA_cont.groupby('UID')['UID'].transform('count')\n",
    "SA_cont = SA_cont.groupby(['UID', 'CUSTOMER_ADVISER']).agg({'n': 'count'}).reset_index()\n",
    "SA_cont.columns = ['UID', 'CUSTOMER_ADVISER', 'count']\n",
    "SA_cont = SA_cont[SA_cont['count'] > 2]\n",
    "SA_cont = SA_cont.drop('count', axis=1)\n",
    "SA_cont['SA_cont'] = 1\n",
    "print(SA_cont.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f467468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_TYPE_DESCRIPTION  UID          GR          PM          BP\n",
      "0                       2  29834346.0   5577289.0   4356000.0\n",
      "1                       4  18477470.0  12674917.0  28275056.0\n",
      "2                       5  36016740.0  24705288.0   9235950.0\n",
      "3                      12   1223000.0   9932832.0   4631220.0\n",
      "4                     262   1301301.0  15972592.0   1718201.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate JOB_m\n",
    "JOB_m = cb[cb['JOB_TYPE_DESCRIPTION'].isin(['Body', 'Paint', 'General Repair', 'Periodic Maintenance'])]\n",
    "JOB_m = JOB_m.groupby(['UID', 'JOB_TYPE_DESCRIPTION']).agg({'GROSS_VALUE': 'sum'}).reset_index()\n",
    "JOB_m.columns = ['UID', 'JOB_TYPE_DESCRIPTION', 'Total_VALUE']\n",
    "JOB_m = JOB_m.pivot(index='UID', columns='JOB_TYPE_DESCRIPTION', values='Total_VALUE').reset_index()\n",
    "JOB_m = JOB_m.fillna(0)\n",
    "JOB_m['BP'] = JOB_m['Paint'] + JOB_m['Body']\n",
    "JOB_m = JOB_m.drop(['Paint', 'Body'], axis=1)\n",
    "JOB_m = JOB_m.rename(columns={'General Repair': 'GR', 'Periodic Maintenance': 'PM'})\n",
    "print(JOB_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b29f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_TYPE_DESCRIPTION  UID  GR_vnum  PM_vnum  BP_vnum\n",
      "0                       2      4.0      5.0      3.0\n",
      "1                       4      9.0      9.0      6.0\n",
      "2                       5     12.0     14.0      5.0\n",
      "3                      12      7.0     10.0      7.0\n",
      "4                     262      4.0     12.0      4.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate JOB_vnum\n",
    "JOB_vnum = cb[cb['JOB_TYPE_DESCRIPTION'].isin(['Body', 'Paint', 'General Repair', 'Periodic Maintenance'])]\n",
    "JOB_vnum = JOB_vnum.groupby(['UID', 'JOB_TYPE_DESCRIPTION']).agg({'DOC_DATE': lambda x: len(x.unique())}).reset_index()\n",
    "JOB_vnum.columns = ['UID', 'JOB_TYPE_DESCRIPTION', 'visit_num']\n",
    "JOB_vnum = JOB_vnum.pivot(index='UID', columns='JOB_TYPE_DESCRIPTION', values='visit_num').reset_index()\n",
    "JOB_vnum = JOB_vnum.fillna(0)\n",
    "JOB_vnum['BP_vnum'] = JOB_vnum['Paint'] + JOB_vnum['Body']\n",
    "JOB_vnum = JOB_vnum.drop(['Paint', 'Body'], axis=1)\n",
    "JOB_vnum = JOB_vnum.rename(columns={'General Repair': 'GR_vnum', 'Periodic Maintenance': 'PM_vnum'})\n",
    "print(JOB_vnum.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595b22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID  TIRE  BATTERY  OIL\n",
      "0    2     0        0    7\n",
      "1    4     0        1   10\n",
      "2    5     0        2   17\n",
      "3   12     0        0    5\n",
      "4  262     0        0    5\n"
     ]
    }
   ],
   "source": [
    "# Calculate TB\n",
    "TB = cb.copy()\n",
    "TB['TIRE'] = TB['DESCRIPTION_ONE'].str.contains('TIRE').astype(int)\n",
    "TB['BATTERY'] = TB['DESCRIPTION_ONE'].str.contains('BATTERY').astype(int)\n",
    "TB['OIL'] = ((TB['DESCRIPTION_ONE'].str.contains('OIL')) & (TB['DESCRIPTION_ONE'].str.contains('HONDA'))).astype(int)\n",
    "TB = TB.groupby('UID').agg({'TIRE': 'sum', 'BATTERY': 'sum', 'OIL': 'sum'}).reset_index()\n",
    "print(TB.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cbb6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID  latest_visit_year  visit_year  visit_rate\n",
      "0    2             2020.0           4    0.500000\n",
      "1    4             2020.0           4    0.500000\n",
      "2    5             2023.0           6    0.750000\n",
      "3   12             2022.0           2    0.666667\n",
      "4  262             2023.0           5    0.833333\n"
     ]
    }
   ],
   "source": [
    "# Calculate PM\n",
    "PM = cb[cb['JOB_TYPE_DESCRIPTION'] == 'Periodic Maintenance']\n",
    "PM = PM.groupby('UID').agg({'DOC_year': ['max', lambda x: len(x.unique())], 'START_year': 'min'}).reset_index()\n",
    "PM.columns = ['UID', 'latest_visit_year', 'visit_year', 'START_year']\n",
    "PM['visit_rate'] = PM['visit_year'] / (year_limit - PM['START_year'])\n",
    "PM = PM.drop('START_year', axis=1)\n",
    "print(PM.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48865fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID      RUN   Total_VALUE  visit_num  keika_max  bad_q  START_year  \\\n",
      "0    2  33265.0  2.616340e+10          9        4.0      0        2016   \n",
      "1    4  49859.0  4.669960e+10         16        4.0      0        2016   \n",
      "2    5  56347.0  8.334043e+10         18        7.0      1        2016   \n",
      "3   12  48717.0  6.261790e+10         15        2.0      0        2021   \n",
      "4  262  35128.0  3.305081e+10         16        6.0      0        2018   \n",
      "\n",
      "  START_date  total_buy  visit_freq_y  ...   BP_freq  PM_freq  TIRE  BATTERY  \\\n",
      "0 2016-10-31          1      2.250000  ...  0.750000     1.25     0        0   \n",
      "1 2016-10-31          1      4.000000  ...  1.500000     2.25     0        1   \n",
      "2 2016-10-31          1      2.571429  ...  0.714286     2.00     0        2   \n",
      "3 2021-09-20          2      7.500000  ...  3.500000     5.00     0        0   \n",
      "4 2018-01-27          2      2.666667  ...  0.666667     2.00     0        0   \n",
      "\n",
      "   OIL  latest_visit_year  visit_year  visit_rate  CUSTOMER_ADVISER  SA_cont  \n",
      "0    7             2020.0         4.0    0.500000               NaN      NaN  \n",
      "1   10             2020.0         4.0    0.500000               NaN      NaN  \n",
      "2   17             2023.0         6.0    0.750000               NaN      NaN  \n",
      "3    5             2022.0         2.0    0.666667        30305050.0      1.0  \n",
      "4    5             2023.0         5.0    0.833333               NaN      NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate smr\n",
    "smr = cb.groupby('UID').agg({'COUNTER_READING': 'max', 'GROSS_VALUE': 'sum', 'SALES_PRICE': 'sum', 'DOC_DATE': lambda x: len(x.unique()), 'keika': 'max', 'bad_q': 'max', 'START_year': 'min', 'WARRANTY_START_DATE': 'min', 'total_buy': 'max'}).reset_index()\n",
    "smr.columns = ['UID', 'RUN', 'Total_VALUE', 'SALES_PRICE', 'visit_num', 'keika_max', 'bad_q', 'START_year', 'START_date', 'total_buy']\n",
    "smr['Total_VALUE'] = smr['Total_VALUE'] + smr['SALES_PRICE']\n",
    "smr = smr.drop('SALES_PRICE', axis=1)\n",
    "smr['visit_freq_y'] = smr['visit_num'] / smr['keika_max']\n",
    "smr = pd.merge(smr, JOB_m, on='UID', how='left')\n",
    "smr = pd.merge(smr, JOB_vnum, on='UID', how='left')\n",
    "smr['TTL'] = smr['BP'] + smr['GR'] + smr['PM']\n",
    "smr['TTL_uni'] = smr['TTL'] / (smr['GR_vnum'] + smr['BP_vnum'] + smr['PM_vnum'])\n",
    "smr['GR_uni'] = smr['GR'] / smr['GR_vnum']\n",
    "smr['BP_uni'] = smr['BP'] / smr['BP_vnum']\n",
    "smr['PM_uni'] = smr['PM'] / smr['PM_vnum']\n",
    "smr['GR_freq'] = smr['GR_vnum'] / smr['keika_max']\n",
    "smr['BP_freq'] = smr['BP_vnum'] / smr['keika_max']\n",
    "smr['PM_freq'] = smr['PM_vnum'] / smr['keika_max']\n",
    "smr = pd.merge(smr, TB, on='UID', how='left')\n",
    "smr = pd.merge(smr, PM, on='UID', how='left')\n",
    "smr = pd.merge(smr, SA_cont, on='UID', how='left')\n",
    "\n",
    "# Backup smr to check (can be removed)\n",
    "smr_backup = smr.copy()\n",
    "print(smr.head())\n",
    "\n",
    "del cb\n",
    "del JOB_m\n",
    "del JOB_vnum\n",
    "del TB\n",
    "del PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3c6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smr.to_csv(output_folder + '/smr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27731fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID  mp_num  mp\n",
      "0    0     109   1\n",
      "1    2       1   1\n",
      "2    4       1   1\n",
      "3    5       1   1\n",
      "4   98       1   1\n"
     ]
    }
   ],
   "source": [
    "# Maintanance Pack\n",
    "mp = pd.read_csv(tmp1_folder + '/mp.csv')\n",
    "mp['UID_count'] = mp['UID'].copy()\n",
    "mp = mp.groupby('UID').agg({'UID_count': 'count'}).reset_index()\n",
    "mp.columns = ['UID', 'mp_num']\n",
    "mp['mp'] = 1\n",
    "print(mp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6378d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files read\n"
     ]
    }
   ],
   "source": [
    "# Read tmp2 files calculated from code 3\n",
    "MH = pd.read_csv(tmp2_folder + '/MH_new_name.csv')\n",
    "\n",
    "chat = pd.read_csv(tmp2_folder + '/chat_output.csv')\n",
    "\n",
    "CR = pd.read_csv(tmp2_folder + '/comp_output.csv')\n",
    "\n",
    "#dcsi\n",
    "dcsi = pd.read_csv(tmp2_folder + '/DCSI_output_ver2.csv')\n",
    "dcsi = dcsi[dcsi['Year'] == dcsi.groupby('UID')['Year'].transform('max')]\n",
    "dcsi.columns = ['UID', 'Month', 'Year', 'Dealer', 'Region', 'satisfaction_reminder', 'satisfaction_reception', 'satisfaction_customer_lounge', 'satisfaction_delivery', 'satisfaction_repair_quality', 'satisfaction_facility', 'one_time_repair', 'total_satisfaction', 'Free_comment', 'follow_call']\n",
    "dcsi = dcsi.groupby('UID').agg({'total_satisfaction': 'mean', 'satisfaction_reminder': 'mean', 'satisfaction_reception': 'mean', 'satisfaction_customer_lounge': 'mean', 'satisfaction_delivery': 'mean', 'satisfaction_repair_quality': 'mean', 'satisfaction_facility': 'mean', 'one_time_repair': 'mean', 'follow_call': 'mean'}).reset_index()\n",
    "\n",
    "ew = pd.read_csv(tmp2_folder + '/ew_output.csv')\n",
    "ew = ew.drop('ew_all_car', axis=1)\n",
    "\n",
    "eve_v_pro = pd.read_csv(tmp2_folder + '/event_v_promo_new_name.csv')\n",
    "#eve_v_pro = eve_v_pro.drop('event_v_promo', axis=1)\n",
    "\n",
    "book = pd.read_csv(tmp2_folder + '/book_new_name.csv')\n",
    "book = book.drop(['UID_counts_book', 'UID有無'], axis=1)\n",
    "\n",
    "test_drive = pd.read_csv(tmp2_folder + '/test_drive_output.csv')\n",
    "\n",
    "estimate_cost = pd.read_csv(tmp2_folder + '/estimate_cost_output.csv')\n",
    "estimate_cost.columns = ['UID', 'estimate_cost']\n",
    "\n",
    "view_product_color = pd.read_csv(tmp2_folder + '/view_product_color_output.csv')\n",
    "view_product_color.columns = ['UID', 'view_product_color']\n",
    "\n",
    "view_product_detail = pd.read_csv(tmp2_folder + '/view_product_detail_am_output.csv')\n",
    "view_product_detail.columns = ['UID', 'view_product_detail']\n",
    "\n",
    "view_product_gallery = pd.read_csv(tmp2_folder + '/view_product_gallery_output.csv')\n",
    "view_product_gallery.columns = ['UID', 'view_product_gallery']\n",
    "\n",
    "view_product_list = pd.read_csv(tmp2_folder + '/view_product_list_output.csv')\n",
    "view_product_list.columns = ['UID', 'view_product_list']\n",
    "\n",
    "view_promotion_notification = pd.read_csv(tmp2_folder + '/view_promotion_notification_output.csv')\n",
    "\n",
    "view_test_drive = pd.read_csv(tmp2_folder + '/view_test_drive_output.csv')\n",
    "\n",
    "sca = pd.read_csv(tmp2_folder + '/SCA_output.csv')\n",
    "\n",
    "notif_book_pi = pd.read_csv(tmp2_folder + '/notif_book_pi_new_name.csv')\n",
    "\n",
    "notif_book_pm = pd.read_csv(tmp2_folder + '/notif_book_pm_new_name.csv')\n",
    "\n",
    "notif_book_spa = pd.read_csv(tmp2_folder + '/notif_book_spa_new_name.csv')\n",
    "\n",
    "notif_v_pro = pd.read_csv(tmp2_folder + '/notif_v_pro_new_name.csv')\n",
    "\n",
    "notif_v_spa = pd.read_csv(tmp2_folder + '/notif_v_spa_new_name.csv')\n",
    "\n",
    "notif_vpi = pd.read_csv(tmp2_folder + '/notif_vpi_new_name.csv')\n",
    "\n",
    "notif_vpm = pd.read_csv(tmp2_folder + '/notif_vpm_new_name.csv')\n",
    "\n",
    "print(\"All files read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b94c8a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned UID fields for data\n"
     ]
    }
   ],
   "source": [
    "mp['UID'] = mp['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "MH['UID'] = MH['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "chat['UID'] = chat['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "CR['UID'] = CR['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "dcsi['UID'] = dcsi['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "ew['UID'] = ew['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "eve_v_pro['UID'] = eve_v_pro['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "book['UID'] = book['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "test_drive['UID'] = test_drive['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "estimate_cost['UID'] = estimate_cost['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_color['UID'] = view_product_color['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_detail['UID'] = view_product_detail['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_gallery['UID'] = view_product_gallery['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_list['UID'] = view_product_list['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_promotion_notification['UID'] = view_promotion_notification['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_test_drive['UID'] = view_test_drive['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "sca['UID'] = sca['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_book_pi['UID'] = notif_book_pi['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_book_pm['UID'] = notif_book_pm['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_book_spa['UID'] = notif_book_spa['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_v_pro['UID'] = notif_v_pro['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_v_spa['UID'] = notif_v_spa['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_vpi['UID'] = notif_vpi['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_vpm['UID'] = notif_vpm['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_vpm['UID'] = notif_vpm['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "tgt['UID'] = tgt['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "print(\"Cleaned UID fields for data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be3fecfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID      RUN   Total_VALUE  visit_num  keika_max  bad_q  START_year  \\\n",
      "0    2  33265.0  2.616340e+10          9        4.0      0        2016   \n",
      "1    4  49859.0  4.669960e+10         16        4.0      0        2016   \n",
      "2    5  56347.0  8.334043e+10         18        7.0      1        2016   \n",
      "3   12  48717.0  6.261790e+10         15        2.0      0        2021   \n",
      "4  262  35128.0  3.305081e+10         16        6.0      0        2018   \n",
      "\n",
      "  START_date  total_buy  visit_freq_y  ...   BP_freq  PM_freq  TIRE  BATTERY  \\\n",
      "0 2016-10-31          1      2.250000  ...  0.750000     1.25     0        0   \n",
      "1 2016-10-31          1      4.000000  ...  1.500000     2.25     0        1   \n",
      "2 2016-10-31          1      2.571429  ...  0.714286     2.00     0        2   \n",
      "3 2021-09-20          2      7.500000  ...  3.500000     5.00     0        0   \n",
      "4 2018-01-27          2      2.666667  ...  0.666667     2.00     0        0   \n",
      "\n",
      "   OIL  latest_visit_year  visit_year  visit_rate  CUSTOMER_ADVISER  SA_cont  \n",
      "0    7             2020.0         4.0    0.500000               NaN      NaN  \n",
      "1   10             2020.0         4.0    0.500000               NaN      NaN  \n",
      "2   17             2023.0         6.0    0.750000               NaN      NaN  \n",
      "3    5             2022.0         2.0    0.666667        30305050.0      1.0  \n",
      "4    5             2023.0         5.0    0.833333               NaN      NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load smr backup to test\n",
    "smr = smr_backup.copy()\n",
    "smr['UID'] = smr['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "print(smr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7780ca03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged with: mp  - column count: 153851\n",
      "Merged with: MH  - column count: 153851\n",
      "Merged with: chat  - column count: 153851\n",
      "Merged with: CR  - column count: 153851\n",
      "Merged with: dcsi  - column count: 153851\n",
      "Merged with: ew  - column count: 153851\n",
      "Merged with: eve_v_pro  - column count: 153851\n",
      "Merged with: book  - column count: 153851\n",
      "Merged with: test_drive  - column count: 153851\n",
      "Merged with: estimate_cost  - column count: 153851\n",
      "Merged with: view_product_color  - column count: 153851\n",
      "Merged with: view_product_detail  - column count: 153851\n",
      "Merged with: view_product_gallery  - column count: 153851\n",
      "Merged with: view_product_list  - column count: 153851\n",
      "Merged with: view_promotion_notification  - column count: 153851\n",
      "Merged with: view_test_drive  - column count: 153851\n",
      "Merged with: sca  - column count: 153851\n",
      "Merged with: notif_book_pi  - column count: 153851\n",
      "Merged with: notif_book_pm  - column count: 153851\n",
      "Merged with: notif_book_spa  - column count: 153851\n",
      "Merged with: notif_v_pro  - column count: 153851\n",
      "Merged with: notif_v_spa  - column count: 153851\n",
      "Merged with: notif_vpi  - column count: 153851\n",
      "Merged with: notif_vpm  - column count: 153851\n",
      "Merged with: tgt  - column count: 153851\n",
      "Data merged\n"
     ]
    }
   ],
   "source": [
    "# Merge smr with other file\n",
    "smr = pd.merge(smr, mp, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"mp\", len(smr)))\n",
    "smr = pd.merge(smr, MH, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"MH\", len(smr)))\n",
    "smr = pd.merge(smr, chat, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"chat\", len(smr)))\n",
    "smr = pd.merge(smr, CR, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"CR\", len(smr)))\n",
    "smr = pd.merge(smr, dcsi, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"dcsi\", len(smr)))\n",
    "smr = pd.merge(smr, ew, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"ew\", len(smr)))\n",
    "smr = pd.merge(smr, eve_v_pro, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"eve_v_pro\", len(smr)))\n",
    "smr = pd.merge(smr, book, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"book\", len(smr)))\n",
    "smr = pd.merge(smr, test_drive, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"test_drive\", len(smr)))\n",
    "smr = pd.merge(smr, estimate_cost, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"estimate_cost\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_color, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_color\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_detail, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_detail\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_gallery, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_gallery\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_list, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_list\", len(smr)))\n",
    "smr = pd.merge(smr, view_promotion_notification, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_promotion_notification\", len(smr)))\n",
    "smr = pd.merge(smr, view_test_drive, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_test_drive\", len(smr)))\n",
    "smr = pd.merge(smr, sca, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"sca\", len(smr)))\n",
    "smr = pd.merge(smr, notif_book_pi, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_book_pi\", len(smr)))\n",
    "smr = pd.merge(smr, notif_book_pm, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_book_pm\", len(smr)))\n",
    "smr = pd.merge(smr, notif_book_spa, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_book_spa\", len(smr)))\n",
    "smr = pd.merge(smr, notif_v_pro, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_v_pro\", len(smr)))\n",
    "smr = pd.merge(smr, notif_v_spa, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_v_spa\", len(smr)))\n",
    "smr = pd.merge(smr, notif_vpi, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_vpi\", len(smr)))\n",
    "smr = pd.merge(smr, notif_vpm, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_vpm\", len(smr)))\n",
    "smr = pd.merge(smr, tgt, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"tgt\", len(smr)))\n",
    "\n",
    "\n",
    "print(\"Data merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422c0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UID      RUN   Total_VALUE  visit_num  keika_max  bad_q  START_year  \\\n",
      "0    2  33265.0  2.616340e+10          9          9      0        2016   \n",
      "1    4  49859.0  4.669960e+10         16          9      0        2016   \n",
      "2    5  56347.0  8.334043e+10         18          9      1        2016   \n",
      "3   12  48717.0  6.261790e+10         15          4      0        2021   \n",
      "4  262  35128.0  3.305081e+10         16          7      0        2018   \n",
      "\n",
      "  START_date  total_buy  visit_freq_y  ...  view_test_drive  sca_visit_num  \\\n",
      "0 2016-10-31          1      2.250000  ...              NaN            NaN   \n",
      "1 2016-10-31          1      4.000000  ...              NaN            NaN   \n",
      "2 2016-10-31          1      2.571429  ...              NaN            NaN   \n",
      "3 2021-09-20          2      7.500000  ...              NaN            NaN   \n",
      "4 2018-01-27          2      2.666667  ...              NaN            NaN   \n",
      "\n",
      "   notif_book_pi  notif_book_pm  notif_book_spa  coupon_view  notif_v_spa  \\\n",
      "0            NaN            NaN             NaN          NaN          NaN   \n",
      "1            NaN            NaN             NaN          NaN          NaN   \n",
      "2            NaN            NaN             NaN          NaN          NaN   \n",
      "3            NaN            NaN             NaN          NaN          NaN   \n",
      "4            NaN            NaN             NaN          NaN          NaN   \n",
      "\n",
      "   notif_vpi  notif_vpm  PM2ov  \n",
      "0        NaN        NaN    0.0  \n",
      "1        NaN        NaN    1.0  \n",
      "2        NaN        NaN    1.0  \n",
      "3        NaN        NaN    1.0  \n",
      "4        NaN        NaN    1.0  \n",
      "\n",
      "[5 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "smr = smr.assign(visit_rate=lambda x: x['visit_rate'].apply(lambda y: 100 if y > 1 else y*100))\n",
    "smr = smr.assign(keika_max=lambda x: year_limit+1-x['START_year'])\n",
    "smr = smr[smr['keika_max'] > 0]\n",
    "#smr = smr.drop(columns=['PM_freq', 'BP_freq', 'GR_freq', 'visit_year'])\n",
    "#smr.drop(columns = ['CUSTOMER_ADVISER', 'visit_num', 'visit_freq_y', 'GR_vnum', 'PM_vnum', 'BP_vnum', 'TTL_uni', 'TTL', 'GR_uni', 'BP_uni', 'PM_uni', 'RUN', 'OIL', 'Total_VALUE', 'GR', 'PM', 'BP', 'ew_sales', 'app_mente_SA_select', 'app_mente_SA_select', 'CR_feedback', 'satisfaction_mechanic', 'mp_num', 'bad_q', 'notif_book_pi', 'notif_book_pm', 'notif_book_spa', 'test_drive', 'follow_call', 'one_time_repair', 'coupon_view', 'view_product_color', 'view_product_gallery', 'chat_num', 'sca_visit_num', 'view_product_list', 'view_promotion_notification', 'MH_Active', 'latest_visit_year', 'service_part'], axis=1, inplace=True)\n",
    "\n",
    "drop_list = [col for col in smr.columns if col.startswith('satisfaction')]\n",
    "drop_list.extend(['PM_freq', 'BP_freq', 'GR_freq', 'visit_year'])\n",
    "drop_list.extend(['CUSTOMER_ADVISER', 'visit_num', 'visit_freq_y', 'GR_vnum', 'PM_vnum', 'BP_vnum', 'TTL_uni', 'TTL', 'GR_uni', 'BP_uni', 'PM_uni', 'RUN', 'OIL', 'Total_VALUE', 'GR', 'PM', 'BP', 'ew_sales', 'app_mente_SA_select', 'app_mente_SA_select', 'CR_feedback', 'satisfaction_mechanic', 'mp_num', 'bad_q', 'notif_book_pi', 'notif_book_pm', 'notif_book_spa', 'test_drive', 'follow_call', 'one_time_repair', 'coupon_view', 'view_product_color', 'view_product_gallery', 'chat_num', 'sca_visit_num', 'view_product_list', 'view_promotion_notification', 'MH_Active', 'latest_visit_year', 'service_part'])\n",
    "drop_list.extend([col for col in smr.columns if col.startswith('UID有無')])\n",
    "cols_to_drop = set(smr.columns).intersection(drop_list)\n",
    "\n",
    "#smr = smr.drop(columns=cols_to_drop)\n",
    "del mp, MH, chat, CR, dcsi, ew, eve_v_pro, book, test_drive, estimate_cost, view_product_color, view_product_detail, view_product_gallery, view_product_list, view_promotion_notification, view_test_drive, sca, notif_book_pi, notif_book_pm, notif_book_spa, notif_v_pro, notif_v_spa, notif_vpi, notif_vpm\n",
    "print(smr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2fd2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to D:\\Software\\temp\\CeDX\\data_2024_05/output/dataset_all_full_columns.csv\n",
      "Index(['UID', 'START_date', 'START_year', 'RUN', 'Total_VALUE', 'visit_num',\n",
      "       'keika_max', 'bad_q', 'total_buy', 'visit_freq_y', 'GR', 'PM', 'BP',\n",
      "       'GR_vnum', 'PM_vnum', 'BP_vnum', 'TTL', 'TTL_uni', 'GR_uni', 'BP_uni',\n",
      "       'PM_uni', 'GR_freq', 'BP_freq', 'PM_freq', 'TIRE', 'BATTERY', 'OIL',\n",
      "       'latest_visit_year', 'visit_year', 'visit_rate', 'CUSTOMER_ADVISER',\n",
      "       'SA_cont', 'mp_num', 'mp', 'MH_Active', 'satisfaction_service',\n",
      "       'satisfaction_mechanic', 'satisfaction_chatbot',\n",
      "       'satisfaction_chatbot_agent', 'MH_ID', 'chat_num', 'service_part',\n",
      "       'chat', 'CR_feedback', 'CR', 'total_satisfaction',\n",
      "       'satisfaction_reminder', 'satisfaction_reception',\n",
      "       'satisfaction_customer_lounge', 'satisfaction_delivery',\n",
      "       'satisfaction_repair_quality', 'satisfaction_facility',\n",
      "       'one_time_repair', 'follow_call', 'ew_sales', 'ew_num', 'event_v_promo',\n",
      "       'coupon_use', 'app_mente_SA_select', 'SA_select', 'app_reserve_mean',\n",
      "       'test_drive', 'estimate_cost', 'view_product_color',\n",
      "       'view_product_detail', 'view_product_gallery', 'view_product_list',\n",
      "       'view_promotion_notification', 'view_test_drive', 'sca_visit_num',\n",
      "       'notif_book_pi', 'notif_book_pm', 'notif_book_spa', 'coupon_view',\n",
      "       'notif_v_spa', 'notif_vpi', 'notif_vpm', 'PM2ov'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Export merged data\n",
    "data = smr[smr['keika_max'] > 0]\n",
    "field_backup = data[['UID', 'START_date', 'START_year']]\n",
    "data = data.drop(['UID', 'START_date', 'START_year'], axis=1)\n",
    "data = data.apply(pd.to_numeric).fillna(0)\n",
    "data = pd.concat([field_backup, data], axis=1)\n",
    "data = data[data['UID'] != 0]\n",
    "data = data[data['UID'] != '0']\n",
    "data = data.rename(columns={'MyHondaæœ‰ç„¡' : 'MH_ID', 'MyHonda有無' : 'MH_ID'})\n",
    "\n",
    "output_data_folder = output_folder + \"/dataset_all_full_columns.csv\"\n",
    "data.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n",
    "print(data.columns)\n",
    "data_backup = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926fbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_backup.tail())\n",
    "# output_data_folder = output_folder + \"/dataset_all_full_columns test.csv\"\n",
    "# data_backup['UID'].to_csv(output_data_folder, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1987869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading service file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24448\\1082347448.py:7: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  service = pd.read_csv(root_folder + '/data/service_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sale file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24448\\1082347448.py:17: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging files\n",
      "Merging with dataset_all_full_columns\n",
      "Export data to D:\\Software\\temp\\CeDX\\data_2024_05/output/dataset_all_full_columns.csv\n"
     ]
    }
   ],
   "source": [
    "def diff_month(d1, d2):\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month\n",
    "\n",
    "year_limit = setts.year_limit\n",
    "end_date_time = setts.month_to\n",
    "print('Reading service file')\n",
    "service = pd.read_csv(root_folder + '/data/service_data.csv')\n",
    "service['DOC_DATE'] = pd.to_datetime(service['DOC_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['DROP_OFF_DATE'] = pd.to_datetime(service['DROP_OFF_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['PICK_UP_DATE'] = pd.to_datetime(service['PICK_UP_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['DOC_year'] = service['DOC_DATE'].dt.year.fillna(0)\n",
    "service['GROSS_VALUE'] = service['GROSS_VALUE'].apply(lambda x: 0 if x < 0 else float(x))\n",
    "service = service[(service['DOC_year'] > 2015) & (service['DOC_year'] <= year_limit)]\n",
    "# service = service.drop(['customer_index', 'Cust_group'], axis=1)\n",
    "\n",
    "print('Reading sale file')\n",
    "sale = pd.read_csv(tmp1_folder + '/sale_uni_min.csv')\n",
    "sale['MODEL'] = sale['MODEL_TEXT_1'].str.split(' ').str[0]\n",
    "sale = sale.drop('MODEL_TEXT_1', axis=1)\n",
    "sale['WARRANTY_START_DATE'] = pd.to_datetime(sale['WARRANTY_START_DATE'], format='%Y-%m-%d')\n",
    "sale['START_year'] = sale['WARRANTY_START_DATE'].dt.year\n",
    "sale = sale[(sale['START_year'] > 2015) & (sale['START_year'] <= year_limit)]\n",
    "sale = sale.drop(['DEALER_CODE'], axis=1)\n",
    "\n",
    "print('Merging files')\n",
    "\n",
    "df = pd.merge(sale, service, on='VIN', how='left')\n",
    "del sale, service\n",
    "\n",
    "df = df[df['DOC_year'] <= year_limit]\n",
    "df['keika'] = np.ceil((df['DOC_DATE'] - df['WARRANTY_START_DATE']).dt.days / 365)\n",
    "df['keika'] = df['keika'].apply(lambda x: 1 if x == 0 else float(x))\n",
    "df = df[df['keika'] > 0]\n",
    "\n",
    "\n",
    "df = df[['UID', 'DOC_DATE', 'JOB_TYPE_DESCRIPTION']]\n",
    "# df = df[df['JOB_TYPE_DESCRIPTION'] == 'Periodic Maintenance']\n",
    "df = df.sort_values(by=['DOC_DATE'])\n",
    "df['DOC_DATE'] = df['DOC_DATE'].dt.strftime('%Y%m%d').astype(int)\n",
    "df = df[df['DOC_DATE'] <= end_date_time]\n",
    "df = df.drop_duplicates(subset=['UID'], keep='last')\n",
    "df = df.sort_values(by=['UID'])\n",
    "\n",
    "df['DOC_DATE'] = pd.to_datetime(df['DOC_DATE'], format='%Y%m%d')\n",
    "end_date = pd.to_datetime(str(end_date_time), format='%Y%m%d')\n",
    "df['month_to_' + str(end_date_time)] = (end_date.year - df['DOC_DATE'].dt.year) * 12 + (end_date.month - df['DOC_DATE'].dt.month)\n",
    "\n",
    "df = df[df['UID'] != 0]\n",
    "df = df[df['UID'] != '0']\n",
    "\n",
    "print('Merging with dataset_all_full_columns')\n",
    "\n",
    "\n",
    "output_data_folder = output_folder + \"/dataset_all_full_columns.csv\"\n",
    "dataset_full = pd.read_csv(output_data_folder)\n",
    "dataset_full = pd.merge(dataset_full, df, on='UID', how='left')\n",
    "\n",
    "dataset_full.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19915f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(dataset_full.tail())\n",
    "# output_data_folder = output_folder + \"/dataset_all_full_columns test2.csv\"\n",
    "# dataset_full.to_csv(output_data_folder, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a901d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to D:\\Software\\temp\\CeDX\\data_2024_05/output/dataset_all.csv\n",
      "Index(['UID', 'keika_max', 'total_buy', 'TIRE', 'BATTERY', 'visit_rate',\n",
      "       'SA_cont', 'mp', 'MH_ID', 'chat', 'CR', 'total_satisfaction', 'ew_num',\n",
      "       'coupon_use', 'SA_select', 'app_reserve_mean', 'estimate_cost',\n",
      "       'view_product_detail', 'view_test_drive', 'notif_v_spa', 'notif_vpi',\n",
      "       'notif_vpm', 'PM2ov'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Only keep relevant columns\n",
    "data_shrink = data_backup.copy()\n",
    "data_shrink = data_shrink[['UID', 'keika_max', 'total_buy', 'TIRE', 'BATTERY', 'visit_rate', 'SA_cont', 'mp', 'MH_ID', 'chat', 'CR', 'total_satisfaction', 'ew_num', 'coupon_use', 'SA_select', 'app_reserve_mean', 'estimate_cost', 'view_product_detail', 'view_test_drive', 'notif_v_spa', 'notif_vpi', 'notif_vpm', 'PM2ov']]\n",
    "output_data_folder = output_folder + \"/dataset_all.csv\"\n",
    "data_shrink.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n",
    "print(data_shrink.columns)\n",
    "data_shrink_backup = data_shrink.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77c410",
   "metadata": {},
   "source": [
    "# Apply ML to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a948307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    85605\n",
      "1.0    68246\n",
      "Name: PM2ov, dtype: int64\n",
      "(153851, 22)\n",
      "   UID  keika_max  total_buy  TIRE  BATTERY  visit_rate  SA_cont   mp  MH_ID  \\\n",
      "0    2          9          1     0        0   50.000000      0.0  1.0    0.0   \n",
      "1    4          9          1     0        1   50.000000      0.0  1.0    0.0   \n",
      "2    5          9          1     0        2   75.000000      0.0  1.0    0.0   \n",
      "3   12          4          2     0        0   66.666667      1.0  0.0    0.0   \n",
      "4  262          7          2     0        0   83.333333      0.0  0.0    0.0   \n",
      "\n",
      "   chat  ...  ew_num  coupon_use  SA_select  app_reserve_mean  estimate_cost  \\\n",
      "0   0.0  ...     0.0         0.0        0.0               0.0            0.0   \n",
      "1   0.0  ...     0.0         0.0        0.0               0.0            0.0   \n",
      "2   0.0  ...     0.0         0.0        1.0              12.0            0.0   \n",
      "3   0.0  ...     0.0         0.0        0.0               0.0            0.0   \n",
      "4   1.0  ...     1.0         0.0        0.0               0.0            0.0   \n",
      "\n",
      "   view_product_detail  view_test_drive  notif_v_spa  notif_vpi  notif_vpm  \n",
      "0                  0.0              0.0          0.0        0.0        0.0  \n",
      "1                  0.0              0.0          0.0        0.0        0.0  \n",
      "2                  0.0              0.0          0.0        0.0        0.0  \n",
      "3                  0.0              0.0          0.0        0.0        0.0  \n",
      "4                  0.0              0.0          0.0        0.0        0.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data_shrink_backup.copy()\n",
    "PM2ov = data['PM2ov']\n",
    "data = data.drop('PM2ov', axis=1)\n",
    "print(pd.Series(PM2ov).value_counts())\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d86aee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to D:\\Software\\temp\\CeDX\\data_2024_05/output/dataset_all_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = data_shrink_backup.copy()\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(data)\n",
    "z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "output_data_folder = output_folder + \"/dataset_all_scaled.csv\"\n",
    "z.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efddefa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6554\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.68      0.69     17068\n",
      "         1.0       0.61      0.62      0.62     13703\n",
      "\n",
      "    accuracy                           0.66     30771\n",
      "   macro avg       0.65      0.65      0.65     30771\n",
      "weighted avg       0.66      0.66      0.66     30771\n",
      "\n",
      "ROC AUC Score: 0.7145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(data)\n",
    "z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "z['PM2ov'] = PM2ov\n",
    "\n",
    "X = z.drop('PM2ov', axis=1)\n",
    "y = z['PM2ov']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "data_out = data_shrink_backup.copy()\n",
    "data_out['Score'] = rf_model.predict_proba(X)[:, 1]\n",
    "output_data_folder = output_folder + \"/dataset_all_scored_rf.csv\"\n",
    "data_out.to_csv(output_data_folder, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8b9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy after tuning: 0.7150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy after tuning: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da3b701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Based on p-values:\n",
      "Feature 3, p-value: 0.0000\n",
      "Feature 4, p-value: 0.0000\n",
      "Feature 5, p-value: 0.0000\n",
      "Feature 6, p-value: 0.0000\n",
      "Feature 14, p-value: 0.0000\n",
      "Feature 15, p-value: 0.0000\n",
      "Feature 9, p-value: 0.0000\n",
      "Feature 8, p-value: 0.0000\n",
      "Feature 7, p-value: 0.0000\n",
      "Feature 11, p-value: 0.0000\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best parameters found:  {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy after feature selection & tuning: 0.7153\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings for cleaner output\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ Load Data (Replace with Your Dataset)\n",
    "# ================================\n",
    "# Assuming X and y are already defined\n",
    "# X = df.drop(columns=['target'])  # Features\n",
    "# y = df['target']  # Target variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ Feature Selection Using p-value (ANOVA F-test)\n",
    "# ================================\n",
    "selector = SelectKBest(score_func=f_classif, k=10)  # Select top 10 features\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get p-values\n",
    "p_values = selector.pvalues_\n",
    "selected_features = np.argsort(p_values)[:10]  # Select features with lowest p-values\n",
    "\n",
    "# Print selected features\n",
    "print(\"Selected Features Based on p-values:\")\n",
    "for i in selected_features:\n",
    "    print(f\"Feature {i}, p-value: {p_values[i]:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ Apply Polynomial Features (Degree 2)\n",
    "# ================================\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train_selected)\n",
    "X_test_poly = poly.transform(X_test_selected)\n",
    "\n",
    "# ================================\n",
    "# 4️⃣ Train Random Forest with Hyperparameter Tuning\n",
    "# ================================\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_poly, y_train)\n",
    "\n",
    "# ================================\n",
    "# 5️⃣ Evaluate Best Model\n",
    "# ================================\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_rf_model.predict(X_test_poly)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy after feature selection & tuning: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51972375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Logistic Regression Accuracy: 0.7134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_poly, y_train)\n",
    "y_pred_base = logreg.predict(X_test_poly)\n",
    "baseline_acc = accuracy_score(y_test, y_pred_base)\n",
    "\n",
    "print(f\"Baseline Logistic Regression Accuracy: {baseline_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f82077b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with polynomial features: 0.6635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Train the Random Forest model with polynomial features\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_poly, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "X_test_poly = poly.transform(X_test)\n",
    "y_pred = rf_model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with polynomial features: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d61770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Train the Random Forest model with polynomial features\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_poly, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "X_test_poly = poly.transform(X_test)\n",
    "y_pred = rf_model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with polynomial features: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f0ab98e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               UID  keika_max  total_buy      TIRE   BATTERY  visit_rate  \\\n",
      "0        -0.133491   1.936144  -0.105263 -0.247642 -0.497694   -0.530917   \n",
      "1        -0.133491   1.936144  -0.105263 -0.247642  0.932332   -0.530917   \n",
      "2        -0.133491   1.936144  -0.105263 -0.247642  2.362359    0.221530   \n",
      "3        -0.133491  -0.482794   2.490072 -0.247642 -0.497694   -0.029286   \n",
      "4        -0.133491   0.968569   2.490072 -0.247642 -0.497694    0.472345   \n",
      "...            ...        ...        ...       ...       ...         ...   \n",
      "153846  124.628222   1.936144  -0.105263 -0.247642  2.362359   -0.154694   \n",
      "153847  126.190188   0.484781  -0.105263 -0.247642  0.932332    0.372019   \n",
      "153848  131.271296   0.968569  -0.105263 -0.247642 -0.497694    0.472345   \n",
      "153849  131.516259   1.936144  -0.105263 -0.247642  0.932332    0.221530   \n",
      "153850  131.724065   1.936144  -0.105263 -0.247642 -0.497694   -0.907141   \n",
      "\n",
      "         SA_cont        mp     MH_ID      chat  ...  coupon_use  SA_select  \\\n",
      "0      -0.521950  2.496305 -0.393087 -0.607414  ...    -0.20735  -0.803354   \n",
      "1      -0.521950  2.496305 -0.393087 -0.607414  ...    -0.20735  -0.803354   \n",
      "2      -0.521950  2.496305 -0.393087 -0.607414  ...    -0.20735   1.244782   \n",
      "3       1.915892 -0.400592 -0.393087 -0.607414  ...    -0.20735  -0.803354   \n",
      "4      -0.521950 -0.400592 -0.393087  1.646324  ...    -0.20735  -0.803354   \n",
      "...          ...       ...       ...       ...  ...         ...        ...   \n",
      "153846 -0.521950 -0.400592 -0.393087 -0.607414  ...    -0.20735  -0.803354   \n",
      "153847 -0.521950 -0.400592 -0.393087 -0.607414  ...    -0.20735  -0.803354   \n",
      "153848 -0.521950 -0.400592 -0.393087  1.646324  ...    -0.20735   1.244782   \n",
      "153849 -0.521950 -0.400592 -0.393087  1.646324  ...    -0.20735   1.244782   \n",
      "153850 -0.521950 -0.400592 -0.393087 -0.607414  ...    -0.20735  -0.803354   \n",
      "\n",
      "        app_reserve_mean  estimate_cost  view_product_detail  view_test_drive  \\\n",
      "0              -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "1              -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "2               2.662313      -0.077446            -0.156549         -0.06143   \n",
      "3              -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "4              -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "...                  ...            ...                  ...              ...   \n",
      "153846         -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "153847         -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "153848          0.912023      -0.077446            -0.156549         -0.06143   \n",
      "153849         -0.088142      -0.077446            -0.156549         -0.06143   \n",
      "153850         -0.338183      -0.077446            -0.156549         -0.06143   \n",
      "\n",
      "        notif_v_spa  notif_vpi  notif_vpm  PM2ov  \n",
      "0         -0.093027  -0.091811  -0.315998    0.0  \n",
      "1         -0.093027  -0.091811  -0.315998    1.0  \n",
      "2         -0.093027  -0.091811  -0.315998    1.0  \n",
      "3         -0.093027  -0.091811  -0.315998    1.0  \n",
      "4         -0.093027  -0.091811  -0.315998    1.0  \n",
      "...             ...        ...        ...    ...  \n",
      "153846    -0.093027  -0.091811  -0.315998    0.0  \n",
      "153847    -0.093027  -0.091811  -0.315998    0.0  \n",
      "153848    -0.093027  -0.091811  -0.315998    1.0  \n",
      "153849    -0.093027  -0.091811  -0.315998    0.0  \n",
      "153850    -0.093027  -0.091811  -0.315998    1.0  \n",
      "\n",
      "[153851 rows x 23 columns]\n",
      "Removed CR\n",
      "Removed notif_vpi\n",
      "Removed view_test_drive\n",
      "Removed total_buy\n",
      "Removed view_product_detail\n",
      "Removed notif_v_spa\n",
      "Removed SA_select:SA_cont\n",
      "171364.193224685\n",
      "PM2ov~keika_max + TIRE + BATTERY + visit_rate + mp + MH_ID + chat + total_satisfaction + ew_num + coupon_use + SA_select + app_reserve_mean + estimate_cost + notif_vpm + SA_cont + visit_rate:keika_max+SA_select:SA_cont\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  PM2ov   No. Observations:               153851\n",
      "Model:                            GLM   Df Residuals:                   153827\n",
      "Model Family:                Binomial   Df Model:                           23\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -85658.\n",
      "Date:                Tue, 25 Mar 2025   Deviance:                   1.7132e+05\n",
      "Time:                        12:59:43   Pearson chi2:                 1.54e+05\n",
      "No. Iterations:                    20   Pseudo R-squ. (CS):             0.2290\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.3654      0.296     -1.233      0.218      -0.946       0.215\n",
      "keika_max               -0.0633      0.007     -9.096      0.000      -0.077      -0.050\n",
      "total_buy                0.0034      0.007      0.510      0.610      -0.010       0.016\n",
      "TIRE                     0.1514      0.007     23.269      0.000       0.139       0.164\n",
      "BATTERY                  0.1597      0.006     24.876      0.000       0.147       0.172\n",
      "visit_rate               1.0691      0.008    131.141      0.000       1.053       1.085\n",
      "mp                       0.0780      0.006     13.586      0.000       0.067       0.089\n",
      "MH_ID                    0.0464      0.006      7.166      0.000       0.034       0.059\n",
      "chat                     0.0498      0.007      7.429      0.000       0.037       0.063\n",
      "CR                      -0.0875     67.096     -0.001      0.999    -131.594     131.419\n",
      "total_satisfaction       0.0383      0.006      6.686      0.000       0.027       0.049\n",
      "ew_num                   0.0336      0.006      5.825      0.000       0.022       0.045\n",
      "coupon_use               0.0241      0.006      3.860      0.000       0.012       0.036\n",
      "SA_select                0.0620      0.007      8.881      0.000       0.048       0.076\n",
      "app_reserve_mean         0.0563      0.007      7.666      0.000       0.042       0.071\n",
      "estimate_cost            0.0125      0.007      1.910      0.056      -0.000       0.025\n",
      "view_product_detail     -0.0051      0.007     -0.769      0.442      -0.018       0.008\n",
      "view_test_drive         -0.0028      0.006     -0.452      0.651      -0.015       0.009\n",
      "notif_v_spa              0.0061      0.006      1.081      0.280      -0.005       0.017\n",
      "notif_vpi               -0.0022      0.006     -0.367      0.714      -0.014       0.009\n",
      "notif_vpm               -0.1100      0.006    -17.191      0.000      -0.122      -0.097\n",
      "SA_cont                  0.1674      0.006     28.942      0.000       0.156       0.179\n",
      "visit_rate:keika_max    -0.1398      0.007    -18.925      0.000      -0.154      -0.125\n",
      "SA_select:SA_cont        0.0073      0.006      1.293      0.196      -0.004       0.018\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# import statsmodels.api as sm\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data = data_shrink_backup.copy()\n",
    "# #data = data.drop('UID', axis=1)\n",
    "# scaler = StandardScaler()\n",
    "# sc = scaler.fit_transform(data)\n",
    "\n",
    "# z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "# z['PM2ov'] = PM2ov\n",
    "# X = z.drop('PM2ov', axis=1)\n",
    "# y = z['PM2ov']\n",
    "\n",
    "# print(z)\n",
    "# formula = \"PM2ov~keika_max + total_buy + TIRE + BATTERY + visit_rate + mp + MH_ID + chat + CR + total_satisfaction + ew_num + coupon_use + SA_select + app_reserve_mean + estimate_cost + view_product_detail + view_test_drive + notif_v_spa + notif_vpi + notif_vpm + SA_cont + visit_rate:keika_max+SA_select:SA_cont\"\n",
    "# #formula = \"PM2ov ~ keika_max + TIRE + BATTERY + visit_rate + mp + chat + CR + ew_num + coupon_use + SA_select + app_reserve_mean + notif_vpm + SA_cont + keika_max:visit_rate\"\n",
    "# model = sm.formula.glm(formula = formula, data = z, family = sm.families.Binomial()).fit()\n",
    "# best_model = model\n",
    "# while True:\n",
    "#     pvalues = best_model.pvalues.drop('Intercept')\n",
    "#     if pvalues.max() > 0.05:\n",
    "#         worst_feature = pvalues.idxmax()\n",
    "#         print(\"Removed %s\" % (worst_feature))\n",
    "#         new_formula = formula.replace(f\" + {worst_feature}\", \"\")\n",
    "#         #new_formula = new_formula.replace(f\" {worst_feature}:\", \"\")\n",
    "#         #new_formula = new_formula.replace(f\":{worst_feature} \", \"\")\n",
    "#         new_model = sm.formula.glm(formula=new_formula, data=data, family=sm.families.Binomial()).fit()\n",
    "#         if new_model.aic < best_model.aic:\n",
    "#             best_model = new_model\n",
    "#             formula = new_formula\n",
    "#         else:\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "# # View the final model summary\n",
    "# print(model.aic)\n",
    "# print(formula)\n",
    "# print(model.summary())\n",
    "# data_out = data_shrink_backup.copy()\n",
    "# data_out['Score'] = model.fittedvalues\n",
    "# output_data_folder = output_folder + \"/dataset_all_scored.csv\"\n",
    "# data_out.to_csv(output_data_folder, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235af90f",
   "metadata": {},
   "source": [
    "## Only run code below to test HM's dataset_all"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bd8f2f5",
   "metadata": {},
   "source": [
    "# import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#data = data_backup.copy()\n",
    "data = pd.read_csv(r\"data\\5_analysis_data\\dataset_all.csv\", encoding='utf-8')\n",
    "PM2ov = data['PM2ov']\n",
    "data = data.drop('PM2ov', axis=1)\n",
    "data = data.drop('UID', axis=1)\n",
    "\n",
    "#print(data.head())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(data)\n",
    "\n",
    "z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "z['PM2ov'] = PM2ov\n",
    "X = z.drop('PM2ov', axis=1)\n",
    "y = z['PM2ov']\n",
    "print(z['PM2ov'])\n",
    "\n",
    "formula = \"PM2ov~keika_max + total_buy + TIRE + BATTERY + visit_rate + mp + MH_ID + chat + CR + total_satisfaction + ew_num + coupon_use + SA_select + app_reserve_mean + estimate_cost + view_product_detail + view_test_drive + notif_v_spa + notif_vpi + notif_vpm + SA_cont + visit_rate:keika_max+SA_select:SA_cont\"\n",
    "\n",
    "#formula = \"PM2ov~keika_max + estimate_cost\"\n",
    "model = sm.formula.glm(formula = formula, data = z, family = sm.families.Binomial()).fit()\n",
    "best_model = model\n",
    "while True:\n",
    "    pvalues = best_model.pvalues.drop('Intercept')\n",
    "    if pvalues.max() > 0.05:\n",
    "        worst_feature = pvalues.idxmax()\n",
    "        print(\"Removed %s\" % (worst_feature))\n",
    "        new_formula = formula.replace(f\" + {worst_feature}\", \"\")\n",
    "        new_formula = new_formula.replace(f\" {worst_feature}:\", \"\")\n",
    "        new_formula = new_formula.replace(f\":{worst_feature} \", \"\")\n",
    "        new_model = sm.formula.glm(formula=new_formula, data=data, family=sm.families.Binomial()).fit()\n",
    "        if new_model.aic < best_model.aic:\n",
    "            best_model = new_model\n",
    "            formula = new_formula\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# View the final model summary\n",
    "print(model.aic)\n",
    "print(formula)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dada72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model after creating it\n",
    "model.save(output_folder + '/customer_engagement_index_model.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "976ebdb6",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "X_test = X.iloc[:2, :]\n",
    "print(X_test)\n",
    "\n",
    "predict_model = sm.load('customer_engagement_index_model.pkl')\n",
    "predictions = model.predict(X_test)\n",
    "print(\"=\" * 50)\n",
    "print(predictions.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a0359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c8ac3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept              -0.365445\n",
      "keika_max              -0.063252\n",
      "total_buy               0.003367\n",
      "TIRE                    0.151353\n",
      "BATTERY                 0.159683\n",
      "visit_rate              1.069068\n",
      "mp                      0.078041\n",
      "MH_ID                   0.046397\n",
      "chat                    0.049824\n",
      "CR                     -0.087488\n",
      "total_satisfaction      0.038274\n",
      "ew_num                  0.033613\n",
      "coupon_use              0.024102\n",
      "SA_select               0.062005\n",
      "app_reserve_mean        0.056309\n",
      "estimate_cost           0.012452\n",
      "view_product_detail    -0.005127\n",
      "view_test_drive        -0.002808\n",
      "notif_v_spa             0.006080\n",
      "notif_vpi              -0.002160\n",
      "notif_vpm              -0.109962\n",
      "SA_cont                 0.167446\n",
      "visit_rate:keika_max   -0.139780\n",
      "SA_select:SA_cont       0.007342\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "model_path = output_folder + \"/customer_engagement_index_model.pkl\"\n",
    "\n",
    "# load the saved model from file\n",
    "model = sm.load(model_path)\n",
    "#print(model.summary())\n",
    "#print(dir(model.params))\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94334e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
