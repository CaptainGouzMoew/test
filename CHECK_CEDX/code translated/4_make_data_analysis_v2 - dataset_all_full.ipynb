{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713a7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb44ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working folder\n",
    "root_folder = r\"D:\\Software\\temp\\CeDX\\data\" # <========= CHANGE THIS LINE TO ROOT FOLDER of data\n",
    "tmp1_folder = root_folder + \"/data/tmp\"\n",
    "tmp2_folder = root_folder + \"/data/tmp2\"\n",
    "input_folder = root_folder + \"/input\"\n",
    "output_folder = root_folder + \"/output\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "year_limit = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b28349a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_11732\\2821949603.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  service = pd.read_csv(root_folder + '/data/service_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read processed service data from code 1\n",
    "service = pd.read_csv(root_folder + '/data/service_data.csv')\n",
    "service['DOC_DATE'] = pd.to_datetime(service['DOC_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['DROP_OFF_DATE'] = pd.to_datetime(service['DROP_OFF_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['PICK_UP_DATE'] = pd.to_datetime(service['PICK_UP_DATE'], format='%Y%m%d', errors='coerce')\n",
    "service['DOC_year'] = service['DOC_DATE'].dt.year.fillna(0)\n",
    "service['GROSS_VALUE'] = service['GROSS_VALUE'].apply(lambda x: 0 if x < 0 else float(x))\n",
    "service = service[(service['DOC_year'] > 2015) & (service['DOC_year'] <= year_limit)]\n",
    "#service = service.drop(['customer_index', 'Cust_group'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a7e9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_11732\\3623793725.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sale = pd.read_csv(input_folder + '/sale_uni_min.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read processed sales data from code 2\n",
    "sale = pd.read_csv(input_folder + '/sale_uni_min.csv')\n",
    "sale['MODEL'] = sale['MODEL_TEXT_1'].str.split(' ').str[0]\n",
    "sale = sale.drop('MODEL_TEXT_1', axis=1)\n",
    "sale['WARRANTY_START_DATE'] = pd.to_datetime(sale['WARRANTY_START_DATE'], format='%Y-%m-%d')\n",
    "sale['START_year'] = sale['WARRANTY_START_DATE'].dt.year\n",
    "sale = sale[(sale['START_year'] > 2015) & (sale['START_year'] <= year_limit)]\n",
    "# sale = sale.drop(['DEALER_CODE', 'customer_index', 'Cust_group'], axis=1)\n",
    "sale = sale.drop(['DEALER_CODE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f152650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CUSTOMER_CODE_x  PARTNER_CATEGORY  TITLE CUSTOMER_NAME GENDER          UID  \\\n",
      "0       2000000000                 1    2.0   Lê Anh Quân   Male  913234781.0   \n",
      "1       2000000000                 1    2.0   Lê Anh Quân   Male  913234781.0   \n",
      "2       2000000000                 1    2.0   Lê Anh Quân   Male  913234781.0   \n",
      "3       2000000000                 1    2.0   Lê Anh Quân   Male  913234781.0   \n",
      "4       2000000000                 1    2.0   Lê Anh Quân   Male  913234781.0   \n",
      "\n",
      "   DATEOFBIRTH OCCUPATION  REGION    CITY  ... GROSS_VALUE ORDER_STATUS  \\\n",
      "0          NaN        NaN       1  Hà Nội  ...     50600.0         H060   \n",
      "1          NaN        NaN       1  Hà Nội  ...   1741344.0         H060   \n",
      "2          NaN        NaN       1  Hà Nội  ...         0.0         H060   \n",
      "3          NaN        NaN       1  Hà Nội  ...    303600.0         H070   \n",
      "4          NaN        NaN       1  Hà Nội  ...    506000.0         H070   \n",
      "\n",
      "  CUSTOMER_ADVISER  JOB  JOB_TYPE JOB_TYPE_DESCRIPTION  \\\n",
      "0       10405006.0  1.0        07             Warranty   \n",
      "1       10405006.0  1.0        07             Warranty   \n",
      "2       10105048.0  1.0        09            Promotion   \n",
      "3       10405020.0  2.0        03       General Repair   \n",
      "4       10405020.0  3.0        03       General Repair   \n",
      "\n",
      "                DESCRIPTION_ONE DOC_year keika  bad_q  \n",
      "0            Nhân công bảo hành   2017.0   1.0      1  \n",
      "1             FOB ASSY_ENTRY KE   2017.0   1.0      1  \n",
      "2  KIEM TRA MIEN PHI 7 HANG MUC   2017.0   1.0      0  \n",
      "3                       Service   2019.0   3.0      0  \n",
      "4            thông xúc kim phun   2019.0   3.0      0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Join sale and service data based on UID, left join\n",
    "#service = service.rename(columns={'VIN' : 'UID'})\n",
    "cb = pd.merge(sale, right=service, how='left', left_on= 'VIN',right_on='VIN')\n",
    "\n",
    "# Calculate number of years between DOC_DATE and WARRANTY_START_DATE\n",
    "cb['keika'] = np.ceil((cb['DOC_DATE'] - cb['WARRANTY_START_DATE']).dt.days / 365)\n",
    "\n",
    "# ?\n",
    "#cb['keika'] = cb['keika'].replace([np.inf, -np.inf], np.nan)\n",
    "cb['keika'] = cb['keika'].apply(lambda x: 1 if x == 0 else float(x))\n",
    "# Warranty = JOB_Type 07\n",
    "cb['bad_q'] = cb['JOB_TYPE'].apply(lambda x: 0 if pd.isna(x) else (1 if x == 7 or str(x) == '07' or str(x) == '7' else 0))\n",
    "cb = cb[cb['keika'] > 0]\n",
    "\n",
    "del sale, service\n",
    "print(cb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53c2c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.to_csv(output_folder + '/merged_sale_service.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9028f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          UID  PM2ov\n",
      "0         0.0      0\n",
      "1  10920827.0      0\n",
      "2  15768909.0      1\n",
      "3  70209999.0      1\n",
      "4  76716756.0      0\n"
     ]
    }
   ],
   "source": [
    "# Calculate tgt v2\n",
    "tgt = cb[cb['JOB_TYPE_DESCRIPTION'] == 'Periodic Maintenance']\n",
    "tgt = tgt.groupby('UID').agg({'DOC_DATE': lambda x: len(x.unique()), 'keika': 'max'}).reset_index()\n",
    "tgt.columns = ['UID', 'PM', 'keika_max']\n",
    "tgt['freq'] = tgt['PM'] / tgt['keika_max']\n",
    "tgt = tgt[tgt['freq'] < 11]\n",
    "tgt['PM_num'] = np.floor(tgt['freq'])\n",
    "tgt['PM2ov'] = tgt['PM_num'].apply(lambda x: 1 if x >= 2 else 0)\n",
    "tgt = tgt[['UID', 'PM2ov']]\n",
    "print(tgt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1f0c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            UID  CUSTOMER_ADVISER  SA_cont\n",
      "0           0.0        20405002.0        1\n",
      "24  112259319.0        10405020.0        1\n",
      "48  128757808.0        21005014.0        1\n",
      "56  151959200.0        10805017.0        1\n",
      "63  164333198.0        20705016.0        1\n"
     ]
    }
   ],
   "source": [
    "# Calculate SA_cont\n",
    "cb = cb[cb['DOC_year'] < year_limit]\n",
    "SA_cont = cb[['UID', 'DOC_DATE', 'CUSTOMER_ADVISER']].drop_duplicates()\n",
    "SA_cont['rank'] = SA_cont.groupby('UID')['DOC_DATE'].rank()\n",
    "max_rank = SA_cont.groupby('UID')['rank'].transform('max')\n",
    "SA_cont = SA_cont[SA_cont['rank'] > max_rank - 3]\n",
    "SA_cont['n'] = SA_cont.groupby('UID')['UID'].transform('count')\n",
    "SA_cont = SA_cont.groupby(['UID', 'CUSTOMER_ADVISER']).agg({'n': 'count'}).reset_index()\n",
    "SA_cont.columns = ['UID', 'CUSTOMER_ADVISER', 'count']\n",
    "SA_cont = SA_cont[SA_cont['count'] > 2]\n",
    "SA_cont = SA_cont.drop('count', axis=1)\n",
    "SA_cont['SA_cont'] = 1\n",
    "print(SA_cont.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f467468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_TYPE_DESCRIPTION         UID         GR         PM         BP\n",
      "0                            0.0        0.0    11000.0        0.0\n",
      "1                     15768909.0        0.0    55000.0   110000.0\n",
      "2                     70209999.0        0.0  2085840.0        0.0\n",
      "3                     76716756.0  1188220.0        0.0        0.0\n",
      "4                     90492647.0  1155000.0  2998166.0  7986000.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate JOB_m\n",
    "JOB_m = cb[cb['JOB_TYPE_DESCRIPTION'].isin(['Body', 'Paint', 'General Repair', 'Periodic Maintenance'])]\n",
    "JOB_m = JOB_m.groupby(['UID', 'JOB_TYPE_DESCRIPTION']).agg({'GROSS_VALUE': 'sum'}).reset_index()\n",
    "JOB_m.columns = ['UID', 'JOB_TYPE_DESCRIPTION', 'Total_VALUE']\n",
    "JOB_m = JOB_m.pivot(index='UID', columns='JOB_TYPE_DESCRIPTION', values='Total_VALUE').reset_index()\n",
    "JOB_m = JOB_m.fillna(0)\n",
    "JOB_m['BP'] = JOB_m['Paint'] + JOB_m['Body']\n",
    "JOB_m = JOB_m.drop(['Paint', 'Body'], axis=1)\n",
    "JOB_m = JOB_m.rename(columns={'General Repair': 'GR', 'Periodic Maintenance': 'PM'})\n",
    "print(JOB_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56b29f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_TYPE_DESCRIPTION         UID  GR_vnum  PM_vnum  BP_vnum\n",
      "0                            0.0      1.0      1.0      1.0\n",
      "1                     15768909.0      0.0      1.0      1.0\n",
      "2                     70209999.0      0.0      2.0      0.0\n",
      "3                     76716756.0      1.0      0.0      0.0\n",
      "4                     90492647.0      2.0      2.0      1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate JOB_vnum\n",
    "JOB_vnum = cb[cb['JOB_TYPE_DESCRIPTION'].isin(['Body', 'Paint', 'General Repair', 'Periodic Maintenance'])]\n",
    "JOB_vnum = JOB_vnum.groupby(['UID', 'JOB_TYPE_DESCRIPTION']).agg({'DOC_DATE': lambda x: len(x.unique())}).reset_index()\n",
    "JOB_vnum.columns = ['UID', 'JOB_TYPE_DESCRIPTION', 'visit_num']\n",
    "JOB_vnum = JOB_vnum.pivot(index='UID', columns='JOB_TYPE_DESCRIPTION', values='visit_num').reset_index()\n",
    "JOB_vnum = JOB_vnum.fillna(0)\n",
    "JOB_vnum['BP_vnum'] = JOB_vnum['Paint'] + JOB_vnum['Body']\n",
    "JOB_vnum = JOB_vnum.drop(['Paint', 'Body'], axis=1)\n",
    "JOB_vnum = JOB_vnum.rename(columns={'General Repair': 'GR_vnum', 'Periodic Maintenance': 'PM_vnum'})\n",
    "print(JOB_vnum.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "595b22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          UID  TIRE  BATTERY  OIL\n",
      "0         0.0     0        0    0\n",
      "1  15768909.0     0        0    0\n",
      "2  70209999.0     0        0    0\n",
      "3  76716756.0     0        0    1\n",
      "4  90492647.0     0        0    2\n"
     ]
    }
   ],
   "source": [
    "# Calculate TB\n",
    "TB = cb.copy()\n",
    "TB['TIRE'] = TB['DESCRIPTION_ONE'].str.contains('TIRE').astype(int)\n",
    "TB['BATTERY'] = TB['DESCRIPTION_ONE'].str.contains('BATTERY').astype(int)\n",
    "TB['OIL'] = ((TB['DESCRIPTION_ONE'].str.contains('OIL')) & (TB['DESCRIPTION_ONE'].str.contains('HONDA'))).astype(int)\n",
    "TB = TB.groupby('UID').agg({'TIRE': 'sum', 'BATTERY': 'sum', 'OIL': 'sum'}).reset_index()\n",
    "print(TB.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cbb6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           UID  latest_visit_year  visit_year  visit_rate\n",
      "0          0.0             2022.0           1    0.142857\n",
      "1   15768909.0             2022.0           1    1.000000\n",
      "2   70209999.0             2022.0           1    1.000000\n",
      "3   90492647.0             2022.0           2    0.500000\n",
      "4  108059030.0             2022.0           2    0.666667\n"
     ]
    }
   ],
   "source": [
    "# Calculate PM\n",
    "PM = cb[cb['JOB_TYPE_DESCRIPTION'] == 'Periodic Maintenance']\n",
    "PM = PM.groupby('UID').agg({'DOC_year': ['max', lambda x: len(x.unique())], 'START_year': 'min'}).reset_index()\n",
    "PM.columns = ['UID', 'latest_visit_year', 'visit_year', 'START_year']\n",
    "PM['visit_rate'] = PM['visit_year'] / (year_limit - PM['START_year'])\n",
    "PM = PM.drop('START_year', axis=1)\n",
    "print(PM.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48865fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          UID      RUN   Total_VALUE  visit_num  keika_max  bad_q  START_year  \\\n",
      "0         0.0   2651.0  2.650011e+09          3        7.0      0        2016   \n",
      "1  15768909.0   1000.0  5.763379e+09          3        1.0      0        2022   \n",
      "2  70209999.0  13765.0  9.350061e+09          5        1.0      0        2022   \n",
      "3  76716756.0   1059.0  3.937247e+09          3        1.0      0        2022   \n",
      "4  90492647.0  10428.0  2.175882e+10          5        3.0      1        2019   \n",
      "\n",
      "  START_date  total_buy  visit_freq_y  ...   BP_freq   PM_freq  TIRE  BATTERY  \\\n",
      "0 2016-02-20          3      0.428571  ...  0.142857  0.142857     0        0   \n",
      "1 2022-10-13          1      3.000000  ...  1.000000  1.000000     0        0   \n",
      "2 2022-04-26          1      5.000000  ...  0.000000  2.000000     0        0   \n",
      "3 2022-05-23          1      3.000000  ...  0.000000  0.000000     0        0   \n",
      "4 2019-11-30          1      1.666667  ...  0.333333  0.666667     0        0   \n",
      "\n",
      "   OIL  latest_visit_year  visit_year  visit_rate  CUSTOMER_ADVISER  SA_cont  \n",
      "0    0             2022.0         1.0    0.142857        20405002.0      1.0  \n",
      "1    0             2022.0         1.0    1.000000               NaN      NaN  \n",
      "2    0             2022.0         1.0    1.000000               NaN      NaN  \n",
      "3    1                NaN         NaN         NaN               NaN      NaN  \n",
      "4    2             2022.0         2.0    0.500000               NaN      NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate smr\n",
    "smr = cb.groupby('UID').agg({'COUNTER_READING': 'max', 'GROSS_VALUE': 'sum', 'SALES_PRICE': 'sum', 'DOC_DATE': lambda x: len(x.unique()), 'keika': 'max', 'bad_q': 'max', 'START_year': 'min', 'WARRANTY_START_DATE': 'min', 'total_buy': 'max'}).reset_index()\n",
    "smr.columns = ['UID', 'RUN', 'Total_VALUE', 'SALES_PRICE', 'visit_num', 'keika_max', 'bad_q', 'START_year', 'START_date', 'total_buy']\n",
    "smr['Total_VALUE'] = smr['Total_VALUE'] + smr['SALES_PRICE']\n",
    "smr = smr.drop('SALES_PRICE', axis=1)\n",
    "smr['visit_freq_y'] = smr['visit_num'] / smr['keika_max']\n",
    "smr = pd.merge(smr, JOB_m, on='UID', how='left')\n",
    "smr = pd.merge(smr, JOB_vnum, on='UID', how='left')\n",
    "smr['TTL'] = smr['BP'] + smr['GR'] + smr['PM']\n",
    "smr['TTL_uni'] = smr['TTL'] / (smr['GR_vnum'] + smr['BP_vnum'] + smr['PM_vnum'])\n",
    "smr['GR_uni'] = smr['GR'] / smr['GR_vnum']\n",
    "smr['BP_uni'] = smr['BP'] / smr['BP_vnum']\n",
    "smr['PM_uni'] = smr['PM'] / smr['PM_vnum']\n",
    "smr['GR_freq'] = smr['GR_vnum'] / smr['keika_max']\n",
    "smr['BP_freq'] = smr['BP_vnum'] / smr['keika_max']\n",
    "smr['PM_freq'] = smr['PM_vnum'] / smr['keika_max']\n",
    "smr = pd.merge(smr, TB, on='UID', how='left')\n",
    "smr = pd.merge(smr, PM, on='UID', how='left')\n",
    "smr = pd.merge(smr, SA_cont, on='UID', how='left')\n",
    "\n",
    "# Backup smr to check (can be removed)\n",
    "smr_backup = smr.copy()\n",
    "print(smr.head())\n",
    "\n",
    "del cb\n",
    "del JOB_m\n",
    "del JOB_vnum\n",
    "del TB\n",
    "del PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a3c6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smr.to_csv(output_folder + '/smr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27731fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           UID  mp_num  mp\n",
      "0   76716756.0       1   1\n",
      "1   96871171.0       1   1\n",
      "2  106172217.0       1   1\n",
      "3  106842461.0       1   1\n",
      "4  109008610.0       1   1\n"
     ]
    }
   ],
   "source": [
    "# Maintanance Pack\n",
    "mp = pd.read_csv(tmp1_folder + '/mp.csv')\n",
    "mp['UID_count'] = mp['UID'].copy()\n",
    "mp = mp.groupby('UID').agg({'UID_count': 'count'}).reset_index()\n",
    "mp.columns = ['UID', 'mp_num']\n",
    "mp['mp'] = 1\n",
    "print(mp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6378d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files read\n"
     ]
    }
   ],
   "source": [
    "# Read tmp2 files calculated from code 3\n",
    "MH = pd.read_csv(tmp2_folder + '/MH_new_name.csv')\n",
    "\n",
    "chat = pd.read_csv(tmp2_folder + '/chat_output.csv')\n",
    "\n",
    "CR = pd.read_csv(tmp2_folder + '/comp_output.csv')\n",
    "\n",
    "#dcsi\n",
    "dcsi = pd.read_csv(tmp2_folder + '/DCSI_output_ver2.csv')\n",
    "dcsi = dcsi[dcsi['Year'] == dcsi.groupby('UID')['Year'].transform('max')]\n",
    "dcsi.columns = ['UID', 'Month', 'Year', 'Dealer', 'Region', 'satisfaction_reminder', 'satisfaction_reception', 'satisfaction_customer_lounge', 'satisfaction_delivery', 'satisfaction_repair_quality', 'satisfaction_facility', 'one_time_repair', 'total_satisfaction', 'Free_comment', 'follow_call']\n",
    "dcsi = dcsi.groupby('UID').agg({'total_satisfaction': 'mean', 'satisfaction_reminder': 'mean', 'satisfaction_reception': 'mean', 'satisfaction_customer_lounge': 'mean', 'satisfaction_delivery': 'mean', 'satisfaction_repair_quality': 'mean', 'satisfaction_facility': 'mean', 'one_time_repair': 'mean', 'follow_call': 'mean'}).reset_index()\n",
    "\n",
    "ew = pd.read_csv(tmp2_folder + '/ew_output.csv')\n",
    "ew = ew.drop('ew_all_car', axis=1)\n",
    "\n",
    "eve_v_pro = pd.read_csv(tmp2_folder + '/event_v_promo_new_name.csv')\n",
    "#eve_v_pro = eve_v_pro.drop('event_v_promo', axis=1)\n",
    "\n",
    "book = pd.read_csv(tmp2_folder + '/book_new_name.csv')\n",
    "book = book.drop(['UID_counts_book', 'UID有無'], axis=1)\n",
    "\n",
    "test_drive = pd.read_csv(tmp2_folder + '/test_drive_output.csv')\n",
    "\n",
    "estimate_cost = pd.read_csv(tmp2_folder + '/estimate_cost_output.csv')\n",
    "estimate_cost.columns = ['UID', 'estimate_cost']\n",
    "\n",
    "view_product_color = pd.read_csv(tmp2_folder + '/view_product_color_output.csv')\n",
    "view_product_color.columns = ['UID', 'view_product_color']\n",
    "\n",
    "view_product_detail = pd.read_csv(tmp2_folder + '/view_product_detail_am_output.csv')\n",
    "view_product_detail.columns = ['UID', 'view_product_detail']\n",
    "\n",
    "view_product_gallery = pd.read_csv(tmp2_folder + '/view_product_gallery_output.csv')\n",
    "view_product_gallery.columns = ['UID', 'view_product_gallery']\n",
    "\n",
    "view_product_list = pd.read_csv(tmp2_folder + '/view_product_list_output.csv')\n",
    "view_product_list.columns = ['UID', 'view_product_list']\n",
    "\n",
    "view_promotion_notification = pd.read_csv(tmp2_folder + '/view_promotion_notification_output.csv')\n",
    "\n",
    "view_test_drive = pd.read_csv(tmp2_folder + '/view_test_drive_output.csv')\n",
    "\n",
    "sca = pd.read_csv(tmp2_folder + '/SCA_output.csv')\n",
    "\n",
    "notif_book_pi = pd.read_csv(tmp2_folder + '/notif_book_pi_new_name.csv')\n",
    "\n",
    "notif_book_pm = pd.read_csv(tmp2_folder + '/notif_book_pm_new_name.csv')\n",
    "\n",
    "notif_book_spa = pd.read_csv(tmp2_folder + '/notif_book_spa_new_name.csv')\n",
    "\n",
    "notif_v_pro = pd.read_csv(tmp2_folder + '/notif_v_pro_new_name.csv')\n",
    "\n",
    "notif_v_spa = pd.read_csv(tmp2_folder + '/notif_v_spa_new_name.csv')\n",
    "\n",
    "notif_vpi = pd.read_csv(tmp2_folder + '/notif_vpi_new_name.csv')\n",
    "\n",
    "notif_vpm = pd.read_csv(tmp2_folder + '/notif_vpm_new_name.csv')\n",
    "\n",
    "print(\"All files read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b94c8a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned UID fields for data\n"
     ]
    }
   ],
   "source": [
    "mp['UID'] = mp['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "MH['UID'] = MH['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "chat['UID'] = chat['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "CR['UID'] = CR['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "dcsi['UID'] = dcsi['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "ew['UID'] = ew['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "eve_v_pro['UID'] = eve_v_pro['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "book['UID'] = book['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "test_drive['UID'] = test_drive['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "estimate_cost['UID'] = estimate_cost['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_color['UID'] = view_product_color['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_detail['UID'] = view_product_detail['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_gallery['UID'] = view_product_gallery['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_product_list['UID'] = view_product_list['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_promotion_notification['UID'] = view_promotion_notification['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "view_test_drive['UID'] = view_test_drive['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "sca['UID'] = sca['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_book_pi['UID'] = notif_book_pi['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_book_pm['UID'] = notif_book_pm['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_book_spa['UID'] = notif_book_spa['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_v_pro['UID'] = notif_v_pro['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_v_spa['UID'] = notif_v_spa['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_vpi['UID'] = notif_vpi['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_vpm['UID'] = notif_vpm['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "notif_vpm['UID'] = notif_vpm['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "tgt['UID'] = tgt['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "print(\"Cleaned UID fields for data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be3fecfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UID      RUN   Total_VALUE  visit_num  keika_max  bad_q  START_year  \\\n",
      "0         0   2651.0  2.650011e+09          3        7.0      0        2016   \n",
      "1  15768909   1000.0  5.763379e+09          3        1.0      0        2022   \n",
      "2  70209999  13765.0  9.350061e+09          5        1.0      0        2022   \n",
      "3  76716756   1059.0  3.937247e+09          3        1.0      0        2022   \n",
      "4  90492647  10428.0  2.175882e+10          5        3.0      1        2019   \n",
      "\n",
      "  START_date  total_buy  visit_freq_y  ...   BP_freq   PM_freq  TIRE  BATTERY  \\\n",
      "0 2016-02-20          3      0.428571  ...  0.142857  0.142857     0        0   \n",
      "1 2022-10-13          1      3.000000  ...  1.000000  1.000000     0        0   \n",
      "2 2022-04-26          1      5.000000  ...  0.000000  2.000000     0        0   \n",
      "3 2022-05-23          1      3.000000  ...  0.000000  0.000000     0        0   \n",
      "4 2019-11-30          1      1.666667  ...  0.333333  0.666667     0        0   \n",
      "\n",
      "   OIL  latest_visit_year  visit_year  visit_rate  CUSTOMER_ADVISER  SA_cont  \n",
      "0    0             2022.0         1.0    0.142857        20405002.0      1.0  \n",
      "1    0             2022.0         1.0    1.000000               NaN      NaN  \n",
      "2    0             2022.0         1.0    1.000000               NaN      NaN  \n",
      "3    1                NaN         NaN         NaN               NaN      NaN  \n",
      "4    2             2022.0         2.0    0.500000               NaN      NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load smr backup to test\n",
    "smr = smr_backup.copy()\n",
    "smr['UID'] = smr['UID'].astype(str).apply(lambda x: x.replace(\".0\", \"\"))\n",
    "print(smr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7780ca03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged with: mp  - column count: 126525\n",
      "Merged with: MH  - column count: 126525\n",
      "Merged with: chat  - column count: 126525\n",
      "Merged with: CR  - column count: 126525\n",
      "Merged with: dcsi  - column count: 126525\n",
      "Merged with: ew  - column count: 126525\n",
      "Merged with: eve_v_pro  - column count: 126525\n",
      "Merged with: book  - column count: 126525\n",
      "Merged with: test_drive  - column count: 126525\n",
      "Merged with: estimate_cost  - column count: 126525\n",
      "Merged with: view_product_color  - column count: 126525\n",
      "Merged with: view_product_detail  - column count: 126525\n",
      "Merged with: view_product_gallery  - column count: 126525\n",
      "Merged with: view_product_list  - column count: 126525\n",
      "Merged with: view_promotion_notification  - column count: 126525\n",
      "Merged with: view_test_drive  - column count: 126525\n",
      "Merged with: sca  - column count: 126525\n",
      "Merged with: notif_book_pi  - column count: 126525\n",
      "Merged with: notif_book_pm  - column count: 126525\n",
      "Merged with: notif_book_spa  - column count: 126525\n",
      "Merged with: notif_v_pro  - column count: 126525\n",
      "Merged with: notif_v_spa  - column count: 126525\n",
      "Merged with: notif_vpi  - column count: 126525\n",
      "Merged with: notif_vpm  - column count: 126525\n",
      "Merged with: tgt  - column count: 126525\n",
      "Data merged\n"
     ]
    }
   ],
   "source": [
    "# Merge smr with other file\n",
    "smr = pd.merge(smr, mp, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"mp\", len(smr)))\n",
    "smr = pd.merge(smr, MH, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"MH\", len(smr)))\n",
    "smr = pd.merge(smr, chat, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"chat\", len(smr)))\n",
    "smr = pd.merge(smr, CR, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"CR\", len(smr)))\n",
    "smr = pd.merge(smr, dcsi, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"dcsi\", len(smr)))\n",
    "smr = pd.merge(smr, ew, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"ew\", len(smr)))\n",
    "smr = pd.merge(smr, eve_v_pro, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"eve_v_pro\", len(smr)))\n",
    "smr = pd.merge(smr, book, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"book\", len(smr)))\n",
    "smr = pd.merge(smr, test_drive, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"test_drive\", len(smr)))\n",
    "smr = pd.merge(smr, estimate_cost, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"estimate_cost\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_color, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_color\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_detail, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_detail\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_gallery, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_gallery\", len(smr)))\n",
    "smr = pd.merge(smr, view_product_list, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_product_list\", len(smr)))\n",
    "smr = pd.merge(smr, view_promotion_notification, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_promotion_notification\", len(smr)))\n",
    "smr = pd.merge(smr, view_test_drive, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"view_test_drive\", len(smr)))\n",
    "smr = pd.merge(smr, sca, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"sca\", len(smr)))\n",
    "smr = pd.merge(smr, notif_book_pi, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_book_pi\", len(smr)))\n",
    "smr = pd.merge(smr, notif_book_pm, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_book_pm\", len(smr)))\n",
    "smr = pd.merge(smr, notif_book_spa, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_book_spa\", len(smr)))\n",
    "smr = pd.merge(smr, notif_v_pro, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_v_pro\", len(smr)))\n",
    "smr = pd.merge(smr, notif_v_spa, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_v_spa\", len(smr)))\n",
    "smr = pd.merge(smr, notif_vpi, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_vpi\", len(smr)))\n",
    "smr = pd.merge(smr, notif_vpm, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"notif_vpm\", len(smr)))\n",
    "smr = pd.merge(smr, tgt, on=\"UID\", how='left')\n",
    "print(\"Merged with: %s  - column count: %s\" % (\"tgt\", len(smr)))\n",
    "\n",
    "\n",
    "print(\"Data merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "422c0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          UID      RUN   Total_VALUE  visit_num  keika_max  bad_q  START_year  \\\n",
      "0           0   2651.0  2.650011e+09          3          5      0        2016   \n",
      "4    90492647  10428.0  2.175882e+10          5          2      1        2019   \n",
      "5    98359185     23.0  1.167576e+09          2          1      0        2020   \n",
      "6   108059030  21255.0  6.826858e+09          5          1      0        2020   \n",
      "10  112259319  35979.0  3.106026e+10         11          2      1        2019   \n",
      "\n",
      "   START_date  total_buy  visit_freq_y  ...  view_test_drive  sca_visit_num  \\\n",
      "0  2016-02-20          3      0.428571  ...              NaN            NaN   \n",
      "4  2019-11-30          1      1.666667  ...              NaN            NaN   \n",
      "5  2020-11-30          1      2.000000  ...              NaN            NaN   \n",
      "6  2020-09-29          1      2.500000  ...              NaN            NaN   \n",
      "10 2019-04-23          1      2.750000  ...              NaN            NaN   \n",
      "\n",
      "    notif_book_pi  notif_book_pm  notif_book_spa  coupon_view  notif_v_spa  \\\n",
      "0             NaN            NaN             NaN          NaN          NaN   \n",
      "4             NaN            NaN             NaN          NaN          NaN   \n",
      "5             NaN            NaN             NaN          NaN          NaN   \n",
      "6             NaN            NaN             NaN          NaN          NaN   \n",
      "10            NaN            NaN             NaN          NaN          NaN   \n",
      "\n",
      "    notif_vpi  notif_vpm  PM2ov  \n",
      "0         NaN        NaN    0.0  \n",
      "4         NaN        NaN    0.0  \n",
      "5         NaN        NaN    NaN  \n",
      "6         NaN        NaN    0.0  \n",
      "10        NaN        NaN    1.0  \n",
      "\n",
      "[5 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "smr = smr.assign(visit_rate=lambda x: x['visit_rate'].apply(lambda y: 100 if y > 1 else y*100))\n",
    "smr = smr.assign(keika_max=lambda x: 2021-x['START_year'])\n",
    "smr = smr[smr['keika_max'] > 0]\n",
    "#smr = smr.drop(columns=['PM_freq', 'BP_freq', 'GR_freq', 'visit_year'])\n",
    "#smr.drop(columns = ['CUSTOMER_ADVISER', 'visit_num', 'visit_freq_y', 'GR_vnum', 'PM_vnum', 'BP_vnum', 'TTL_uni', 'TTL', 'GR_uni', 'BP_uni', 'PM_uni', 'RUN', 'OIL', 'Total_VALUE', 'GR', 'PM', 'BP', 'ew_sales', 'app_mente_SA_select', 'app_mente_SA_select', 'CR_feedback', 'satisfaction_mechanic', 'mp_num', 'bad_q', 'notif_book_pi', 'notif_book_pm', 'notif_book_spa', 'test_drive', 'follow_call', 'one_time_repair', 'coupon_view', 'view_product_color', 'view_product_gallery', 'chat_num', 'sca_visit_num', 'view_product_list', 'view_promotion_notification', 'MH_Active', 'latest_visit_year', 'service_part'], axis=1, inplace=True)\n",
    "\n",
    "drop_list = [col for col in smr.columns if col.startswith('satisfaction')]\n",
    "drop_list.extend(['PM_freq', 'BP_freq', 'GR_freq', 'visit_year'])\n",
    "drop_list.extend(['CUSTOMER_ADVISER', 'visit_num', 'visit_freq_y', 'GR_vnum', 'PM_vnum', 'BP_vnum', 'TTL_uni', 'TTL', 'GR_uni', 'BP_uni', 'PM_uni', 'RUN', 'OIL', 'Total_VALUE', 'GR', 'PM', 'BP', 'ew_sales', 'app_mente_SA_select', 'app_mente_SA_select', 'CR_feedback', 'satisfaction_mechanic', 'mp_num', 'bad_q', 'notif_book_pi', 'notif_book_pm', 'notif_book_spa', 'test_drive', 'follow_call', 'one_time_repair', 'coupon_view', 'view_product_color', 'view_product_gallery', 'chat_num', 'sca_visit_num', 'view_product_list', 'view_promotion_notification', 'MH_Active', 'latest_visit_year', 'service_part'])\n",
    "drop_list.extend([col for col in smr.columns if col.startswith('UID有無')])\n",
    "cols_to_drop = set(smr.columns).intersection(drop_list)\n",
    "\n",
    "#smr = smr.drop(columns=cols_to_drop)\n",
    "del mp, MH, chat, CR, dcsi, ew, eve_v_pro, book, test_drive, estimate_cost, view_product_color, view_product_detail, view_product_gallery, view_product_list, view_promotion_notification, view_test_drive, sca, notif_book_pi, notif_book_pm, notif_book_spa, notif_v_pro, notif_v_spa, notif_vpi, notif_vpm\n",
    "print(smr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2fd2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to D:\\Software\\temp\\CeDX\\data/output/dataset_all_full_columns.csv\n",
      "Index(['UID', 'START_date', 'START_year', 'RUN', 'Total_VALUE', 'visit_num',\n",
      "       'keika_max', 'bad_q', 'total_buy', 'visit_freq_y', 'GR', 'PM', 'BP',\n",
      "       'GR_vnum', 'PM_vnum', 'BP_vnum', 'TTL', 'TTL_uni', 'GR_uni', 'BP_uni',\n",
      "       'PM_uni', 'GR_freq', 'BP_freq', 'PM_freq', 'TIRE', 'BATTERY', 'OIL',\n",
      "       'latest_visit_year', 'visit_year', 'visit_rate', 'CUSTOMER_ADVISER',\n",
      "       'SA_cont', 'mp_num', 'mp', 'MH_Active', 'satisfaction_service',\n",
      "       'satisfaction_mechanic', 'satisfaction_chatbot',\n",
      "       'satisfaction_chatbot_agent', 'MH_ID', 'chat_num', 'service_part',\n",
      "       'chat', 'CR_feedback', 'CR', 'total_satisfaction',\n",
      "       'satisfaction_reminder', 'satisfaction_reception',\n",
      "       'satisfaction_customer_lounge', 'satisfaction_delivery',\n",
      "       'satisfaction_repair_quality', 'satisfaction_facility',\n",
      "       'one_time_repair', 'follow_call', 'ew_sales', 'ew_num', 'event_v_promo',\n",
      "       'coupon_use', 'app_mente_SA_select', 'SA_select', 'app_reserve_mean',\n",
      "       'test_drive', 'estimate_cost', 'view_product_color',\n",
      "       'view_product_detail', 'view_product_gallery', 'view_product_list',\n",
      "       'view_promotion_notification', 'view_test_drive', 'sca_visit_num',\n",
      "       'notif_book_pi', 'notif_book_pm', 'notif_book_spa', 'coupon_view',\n",
      "       'notif_v_spa', 'notif_vpi', 'notif_vpm', 'PM2ov'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Export merged data\n",
    "data = smr[smr['keika_max'] > 0]\n",
    "field_backup = data[['UID', 'START_date', 'START_year']]\n",
    "data = data.drop(['UID', 'START_date', 'START_year'], axis=1)\n",
    "data = data.apply(pd.to_numeric).fillna(0)\n",
    "data = pd.concat([field_backup, data], axis=1)\n",
    "data = data[data['UID'] != 0]\n",
    "data = data[data['UID'] != '0']\n",
    "#data = data.drop(['START_date', 'event_v_promo'], axis=1)\n",
    "#data = data.drop(['START_year', 'UID'], axis=1)\n",
    "output_data_folder = output_folder + \"/dataset_all_full_columns.csv\"\n",
    "data.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n",
    "print(data.columns)\n",
    "data_backup = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a901d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to D:\\Software\\temp\\CeDX\\data/output/dataset_all.csv\n",
      "Index(['UID', 'keika_max', 'total_buy', 'TIRE', 'BATTERY', 'visit_rate',\n",
      "       'SA_cont', 'mp', 'MH_ID', 'chat', 'CR', 'total_satisfaction', 'ew_num',\n",
      "       'coupon_use', 'SA_select', 'app_reserve_mean', 'estimate_cost',\n",
      "       'view_product_detail', 'view_test_drive', 'notif_v_spa', 'notif_vpi',\n",
      "       'notif_vpm', 'PM2ov'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Only keep relevant columns\n",
    "data_shrink = data_backup.copy()\n",
    "data_shrink = data_shrink[['UID', 'keika_max', 'total_buy', 'TIRE', 'BATTERY', 'visit_rate', 'SA_cont', 'mp', 'MH_ID', 'chat', 'CR', 'total_satisfaction', 'ew_num', 'coupon_use', 'SA_select', 'app_reserve_mean', 'estimate_cost', 'view_product_detail', 'view_test_drive', 'notif_v_spa', 'notif_vpi', 'notif_vpm', 'PM2ov']]\n",
    "output_data_folder = output_folder + \"/dataset_all.csv\"\n",
    "data_shrink.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n",
    "print(data_shrink.columns)\n",
    "data_shrink_backup = data_shrink.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77c410",
   "metadata": {},
   "source": [
    "# Apply ML to create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a948307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    42697\n",
      "1.0    38640\n",
      "Name: PM2ov, dtype: int64\n",
      "(81337, 22)\n",
      "          UID  keika_max  total_buy  TIRE  BATTERY  visit_rate  SA_cont   mp  \\\n",
      "4    90492647          2          1     0        0   50.000000      0.0  0.0   \n",
      "5    98359185          1          1     0        0    0.000000      0.0  0.0   \n",
      "6   108059030          1          1     0        1   66.666667      0.0  0.0   \n",
      "10  112259319          2          1     0        1  100.000000      1.0  1.0   \n",
      "12  123225861          3          1     0        1   60.000000      0.0  0.0   \n",
      "\n",
      "    MH_ID  chat  ...  ew_num  coupon_use  SA_select  app_reserve_mean  \\\n",
      "4     0.0   0.0  ...     0.0         0.0        1.0               1.0   \n",
      "5     0.0   0.0  ...     0.0         0.0        0.0               0.0   \n",
      "6     0.0   0.0  ...     0.0         0.0        0.0               0.0   \n",
      "10    0.0   1.0  ...     1.0         0.0        0.0               0.0   \n",
      "12    0.0   1.0  ...     0.0         0.0        1.0               2.0   \n",
      "\n",
      "    estimate_cost  view_product_detail  view_test_drive  notif_v_spa  \\\n",
      "4             0.0                  0.0              0.0          0.0   \n",
      "5             0.0                  0.0              0.0          0.0   \n",
      "6             0.0                  0.0              0.0          0.0   \n",
      "10            0.0                  2.0              0.0          0.0   \n",
      "12            1.0                  2.0              0.0          0.0   \n",
      "\n",
      "    notif_vpi  notif_vpm  \n",
      "4         0.0        0.0  \n",
      "5         0.0        0.0  \n",
      "6         0.0        0.0  \n",
      "10        0.0        0.0  \n",
      "12        0.0        0.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = data_shrink_backup.copy()\n",
    "PM2ov = data['PM2ov']\n",
    "data = data.drop('PM2ov', axis=1)\n",
    "print(pd.Series(PM2ov).value_counts())\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d86aee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data to D:\\Software\\temp\\CeDX\\data/output/dataset_all_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = data_shrink_backup.copy()\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(data)\n",
    "z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "output_data_folder = output_folder + \"/dataset_all_scaled.csv\"\n",
    "z.to_csv(output_data_folder, index=False)\n",
    "print(\"Export data to\", output_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f0ab98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             UID  keika_max  total_buy      TIRE   BATTERY  visit_rate  \\\n",
      "4      -5.650972  -0.395099  -0.127401 -0.269743 -0.620792   -0.894343   \n",
      "5      -5.595997  -1.248311  -0.127401 -0.269743 -0.620792   -2.819964   \n",
      "6      -5.528210  -1.248311  -0.127401 -0.269743  0.725411   -0.252469   \n",
      "10     -5.498856  -0.395099  -0.127401 -0.269743  0.725411    1.031279   \n",
      "12     -5.422217   0.458112  -0.127401 -0.269743  0.725411   -0.509218   \n",
      "...          ...        ...        ...       ...       ...         ...   \n",
      "126502  0.689992   2.164534  -0.127401 -0.269743 -0.620792   -2.269786   \n",
      "126503  0.690122  -0.395099  -0.127401 -0.269743 -0.620792   -0.894343   \n",
      "126504  0.690497   0.458112  -0.127401 -0.269743  0.725411   -0.509218   \n",
      "126505  0.697366  -0.395099  -0.127401 -0.269743 -0.620792    0.068468   \n",
      "126506  0.697527   0.458112  -0.127401 -0.269743 -0.620792    0.261030   \n",
      "\n",
      "         SA_cont        mp     MH_ID      chat  ...  coupon_use  SA_select  \\\n",
      "4      -0.559473 -0.378387 -0.364455 -0.603120  ...   -0.256119   1.203540   \n",
      "5      -0.559473 -0.378387 -0.364455 -0.603120  ...   -0.256119  -0.830882   \n",
      "6      -0.559473 -0.378387 -0.364455 -0.603120  ...   -0.256119  -0.830882   \n",
      "10      1.787398  2.642800 -0.364455  1.658045  ...   -0.256119  -0.830882   \n",
      "12     -0.559473 -0.378387 -0.364455  1.658045  ...   -0.256119   1.203540   \n",
      "...          ...       ...       ...       ...  ...         ...        ...   \n",
      "126502 -0.559473 -0.378387 -0.364455 -0.603120  ...   -0.256119  -0.830882   \n",
      "126503 -0.559473 -0.378387  2.743825 -0.603120  ...   -0.256119   1.203540   \n",
      "126504  1.787398 -0.378387 -0.364455 -0.603120  ...   -0.256119  -0.830882   \n",
      "126505  1.787398 -0.378387 -0.364455 -0.603120  ...   -0.256119  -0.830882   \n",
      "126506 -0.559473 -0.378387 -0.364455 -0.603120  ...   -0.256119  -0.830882   \n",
      "\n",
      "        app_reserve_mean  estimate_cost  view_product_detail  view_test_drive  \\\n",
      "4              -0.118633      -0.062014            -0.182008        -0.060947   \n",
      "5              -0.345996      -0.062014            -0.182008        -0.060947   \n",
      "6              -0.345996      -0.062014            -0.182008        -0.060947   \n",
      "10             -0.345996      -0.062014            -0.034739        -0.060947   \n",
      "12              0.108729       1.229678            -0.034739        -0.060947   \n",
      "...                  ...            ...                  ...              ...   \n",
      "126502         -0.345996      -0.062014            -0.182008        -0.060947   \n",
      "126503          1.245542      -0.062014            -0.182008        -0.060947   \n",
      "126504         -0.345996      -0.062014            -0.182008        -0.060947   \n",
      "126505         -0.345996      -0.062014            -0.182008        -0.060947   \n",
      "126506         -0.345996      -0.062014            -0.182008        -0.060947   \n",
      "\n",
      "        notif_v_spa  notif_vpi  notif_vpm  PM2ov  \n",
      "4         -0.127745  -0.096795  -0.349083    0.0  \n",
      "5         -0.127745  -0.096795  -0.349083    0.0  \n",
      "6         -0.127745  -0.096795  -0.349083    0.0  \n",
      "10        -0.127745  -0.096795  -0.349083    1.0  \n",
      "12        -0.127745  -0.096795  -0.349083    0.0  \n",
      "...             ...        ...        ...    ...  \n",
      "126502    -0.127745  -0.096795  -0.349083    0.0  \n",
      "126503    -0.127745  -0.096795  -0.349083    0.0  \n",
      "126504    -0.127745  -0.096795  -0.349083    0.0  \n",
      "126505    -0.127745  -0.096795  -0.349083    0.0  \n",
      "126506    -0.127745  -0.096795  -0.349083    0.0  \n",
      "\n",
      "[81337 rows x 23 columns]\n",
      "Removed total_buy\n",
      "Removed SA_select\n",
      "Removed estimate_cost\n",
      "Removed view_test_drive\n",
      "Removed CR\n",
      "95504.089464444\n",
      "PM2ov~keika_max + TIRE + BATTERY + visit_rate + mp + MH_ID + chat + CR + total_satisfaction + ew_num + coupon_use + app_reserve_mean + view_product_detail + notif_v_spa + notif_vpi + notif_vpm + SA_cont + visit_rate:keika_max+SA_select:SA_cont\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  PM2ov   No. Observations:                81337\n",
      "Model:                            GLM   Df Residuals:                    81314\n",
      "Model Family:                Binomial   Df Model:                           22\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -47729.\n",
      "Date:                Mon, 11 Sep 2023   Deviance:                       95458.\n",
      "Time:                        15:20:51   Pearson chi2:                 8.15e+04\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.1896\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.1709      0.008    -21.258      0.000      -0.187      -0.155\n",
      "keika_max                0.0083      0.008      1.002      0.316      -0.008       0.025\n",
      "total_buy               -0.0039      0.009     -0.457      0.648      -0.021       0.013\n",
      "TIRE                     0.1729      0.009     18.986      0.000       0.155       0.191\n",
      "BATTERY                  0.1961      0.008     23.116      0.000       0.180       0.213\n",
      "visit_rate               0.8924      0.010     90.401      0.000       0.873       0.912\n",
      "mp                       0.0915      0.008     11.609      0.000       0.076       0.107\n",
      "MH_ID                    0.0285      0.009      3.306      0.001       0.012       0.045\n",
      "chat                     0.0591      0.009      6.573      0.000       0.041       0.077\n",
      "CR                    6.401e-17   4.88e-18     13.108      0.000    5.44e-17    7.36e-17\n",
      "total_satisfaction       0.0452      0.008      5.743      0.000       0.030       0.061\n",
      "ew_num                   0.0547      0.008      6.862      0.000       0.039       0.070\n",
      "coupon_use               0.0235      0.009      2.620      0.009       0.006       0.041\n",
      "SA_select                0.0140      0.009      1.519      0.129      -0.004       0.032\n",
      "app_reserve_mean         0.0394      0.009      4.154      0.000       0.021       0.058\n",
      "estimate_cost            0.0058      0.009      0.619      0.536      -0.012       0.024\n",
      "view_product_detail      0.0302      0.011      2.709      0.007       0.008       0.052\n",
      "view_test_drive          0.0086      0.010      0.870      0.385      -0.011       0.028\n",
      "notif_v_spa              0.0182      0.008      2.324      0.020       0.003       0.034\n",
      "notif_vpi               -0.0134      0.008     -1.723      0.085      -0.029       0.002\n",
      "notif_vpm               -0.0631      0.009     -7.054      0.000      -0.081      -0.046\n",
      "SA_cont                  0.2153      0.008     27.314      0.000       0.200       0.231\n",
      "visit_rate:keika_max    -0.0873      0.009     -9.614      0.000      -0.105      -0.069\n",
      "SA_select:SA_cont        0.0191      0.008      2.458      0.014       0.004       0.034\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = data_shrink_backup.copy()\n",
    "#data = data.drop('UID', axis=1)\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(data)\n",
    "\n",
    "z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "z['PM2ov'] = PM2ov\n",
    "X = z.drop('PM2ov', axis=1)\n",
    "y = z['PM2ov']\n",
    "\n",
    "print(z)\n",
    "formula = \"PM2ov~keika_max + total_buy + TIRE + BATTERY + visit_rate + mp + MH_ID + chat + CR + total_satisfaction + ew_num + coupon_use + SA_select + app_reserve_mean + estimate_cost + view_product_detail + view_test_drive + notif_v_spa + notif_vpi + notif_vpm + SA_cont + visit_rate:keika_max+SA_select:SA_cont\"\n",
    "#formula = \"PM2ov ~ keika_max + TIRE + BATTERY + visit_rate + mp + chat + CR + ew_num + coupon_use + SA_select + app_reserve_mean + notif_vpm + SA_cont + keika_max:visit_rate\"\n",
    "model = sm.formula.glm(formula = formula, data = z, family = sm.families.Binomial()).fit()\n",
    "best_model = model\n",
    "while True:\n",
    "    pvalues = best_model.pvalues.drop('Intercept')\n",
    "    if pvalues.max() > 0.05:\n",
    "        worst_feature = pvalues.idxmax()\n",
    "        print(\"Removed %s\" % (worst_feature))\n",
    "        new_formula = formula.replace(f\" + {worst_feature}\", \"\")\n",
    "        #new_formula = new_formula.replace(f\" {worst_feature}:\", \"\")\n",
    "        #new_formula = new_formula.replace(f\":{worst_feature} \", \"\")\n",
    "        new_model = sm.formula.glm(formula=new_formula, data=data, family=sm.families.Binomial()).fit()\n",
    "        if new_model.aic < best_model.aic:\n",
    "            best_model = new_model\n",
    "            formula = new_formula\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# View the final model summary\n",
    "print(model.aic)\n",
    "print(formula)\n",
    "print(model.summary())\n",
    "data_out = data_shrink_backup.copy()\n",
    "data_out['Score'] = model.fittedvalues\n",
    "output_data_folder = output_folder + \"/dataset_all_scored.csv\"\n",
    "data_out.to_csv(output_data_folder, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235af90f",
   "metadata": {},
   "source": [
    "## Only run code below to test HM's dataset_all"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81e7bb8f",
   "metadata": {},
   "source": [
    "# import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#data = data_backup.copy()\n",
    "data = pd.read_csv(r\"data\\5_analysis_data\\dataset_all.csv\", encoding='utf-8')\n",
    "PM2ov = data['PM2ov']\n",
    "data = data.drop('PM2ov', axis=1)\n",
    "data = data.drop('UID', axis=1)\n",
    "\n",
    "#print(data.head())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sc = scaler.fit_transform(data)\n",
    "\n",
    "z = pd.DataFrame(sc, index=data.index, columns=data.columns)\n",
    "z['PM2ov'] = PM2ov\n",
    "X = z.drop('PM2ov', axis=1)\n",
    "y = z['PM2ov']\n",
    "print(z['PM2ov'])\n",
    "\n",
    "formula = \"PM2ov~keika_max + total_buy + TIRE + BATTERY + visit_rate + mp + MH_ID + chat + CR + total_satisfaction + ew_num + coupon_use + SA_select + app_reserve_mean + estimate_cost + view_product_detail + view_test_drive + notif_v_spa + notif_vpi + notif_vpm + SA_cont + visit_rate:keika_max+SA_select:SA_cont\"\n",
    "\n",
    "#formula = \"PM2ov~keika_max + estimate_cost\"\n",
    "model = sm.formula.glm(formula = formula, data = z, family = sm.families.Binomial()).fit()\n",
    "best_model = model\n",
    "while True:\n",
    "    pvalues = best_model.pvalues.drop('Intercept')\n",
    "    if pvalues.max() > 0.05:\n",
    "        worst_feature = pvalues.idxmax()\n",
    "        print(\"Removed %s\" % (worst_feature))\n",
    "        new_formula = formula.replace(f\" + {worst_feature}\", \"\")\n",
    "        new_formula = new_formula.replace(f\" {worst_feature}:\", \"\")\n",
    "        new_formula = new_formula.replace(f\":{worst_feature} \", \"\")\n",
    "        new_model = sm.formula.glm(formula=new_formula, data=data, family=sm.families.Binomial()).fit()\n",
    "        if new_model.aic < best_model.aic:\n",
    "            best_model = new_model\n",
    "            formula = new_formula\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# View the final model summary\n",
    "print(model.aic)\n",
    "print(formula)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dada72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model after creating it\n",
    "model.save('customer_engagement_index_model.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "976ebdb6",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "X_test = X.iloc[:2, :]\n",
    "print(X_test)\n",
    "\n",
    "predict_model = sm.load('customer_engagement_index_model.pkl')\n",
    "predictions = model.predict(X_test)\n",
    "print(\"=\" * 50)\n",
    "print(predictions.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a0359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
