{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'global_settings' from 'C:\\\\Users\\\\AO_HVN_ITS_LABO_DWH\\\\Desktop\\\\CHECK_CEDX\\\\global_settings.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libs\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "import global_settings\n",
    "importlib.reload(global_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data/tmp\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/data/tmp2\n",
      "Directory found: D:\\Software\\temp\\CeDX\\data_2024_05/output\n"
     ]
    }
   ],
   "source": [
    "setts = global_settings.Settings()\n",
    "\n",
    "root_folder = setts.root_folder\n",
    "\n",
    "input_tmp_folder = setts.tmp1_folder\n",
    "output_folder = setts.tmp2_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24408\\3312620703.py:3: DtypeWarning: Columns (2,39,69,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(INPUT_PATH_DCSI, encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "### データの入力\n",
    "INPUT_PATH_DCSI = input_tmp_folder + \"/DCSI.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_DCSI, encoding='utf-8')\n",
    "\n",
    "### カラムの抽出\n",
    "collist = [\n",
    "\"UID\",\n",
    "\"Month\",\n",
    "\"Year\",\n",
    "\"Dealer\",\n",
    "\"Region\",\n",
    "\"REMINDER_\",\n",
    "\"RECEPTION\",\n",
    "\"CUSTOMER_LOUNGE\",\n",
    "\"DELIVERY\",\n",
    "\"REPAIR_QUALITY\",\n",
    "\"FACILITY\",\n",
    "\"Q30Y\",\n",
    "\"OVERALL_SATISFACTION\",\n",
    "\"Free_comment\"\n",
    "]\n",
    "\n",
    "df = df[collist]\n",
    "\n",
    "### データの出力\n",
    "OUTPUT_PATH_DCSI = output_folder + \"/DCSI_ver1.csv\"\n",
    "df.to_csv(OUTPUT_PATH_DCSI, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCSIに関する追加の処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24408\\937043279.py:2: DtypeWarning: Columns (2,39,69,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(INPUT_PATH_DCSI, encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "# データの入力\n",
    "df = pd.read_csv(INPUT_PATH_DCSI, encoding='utf-8')\n",
    "\n",
    "# カラムの抽出・データ型の変換\n",
    "df_DCSI = df[['UID', 'Q35Y']].copy()\n",
    "df_DCSI['follow_call'] = pd.to_numeric(df_DCSI['Q35Y'], errors='coerce')\n",
    "\n",
    "# follow_callごとの処理\n",
    "# Processing each follow call\n",
    "df_DCSI.fillna({'follow_call': 0}, inplace=True)\n",
    "df_DCSI_output = df_DCSI.groupby(by='UID').agg(\n",
    "    follow_call=('follow_call', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# ↑のセルで作成したデータの入力\n",
    "# File created by cell above\n",
    "df_DCSI_new_name = pd.read_csv(OUTPUT_PATH_DCSI)\n",
    "\n",
    "# データの結合\n",
    "df_DCSI_ver2 = pd.merge(df_DCSI_new_name, df_DCSI_output, on = 'UID', how = 'left')\n",
    "\n",
    "# データの出力\n",
    "df_DCSI_ver2.to_csv(output_folder + \"/DCSI_output_ver2.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Honda"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### データの入力\n",
    "INPUT_PATH_MH = input_tmp_folder + \"/MH.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_MH, encoding='utf-8')\n",
    "\n",
    "### カラムの抽出\n",
    "usecols = [\n",
    "    'rate_service_point',\n",
    "    'rate_mechanic_point',\n",
    "    'rate_chatbot_point',\n",
    "    'rate_chatbot_agent_point',\n",
    "    'UID',\n",
    "]\n",
    "\n",
    "df_MH = df[usecols]\n",
    "\n",
    "\n",
    "### 最後の点数を抽出\n",
    "# rate_service_point, rate_mechanic_pointについて、小数表記のため3文字分を抽出\n",
    "# rate_service_point\n",
    "rate_service_point_5str_1 = df_MH.loc[:, 'rate_service_point'].str[-5:-1] \n",
    "rate_service_point_5str_2 = rate_service_point_5str_1.str[-3:]\n",
    "# rate_mechanic_point\n",
    "rate_mechanic_point_5str_1 = df_MH.loc[:, 'rate_mechanic_point'].str[-5:-1] \n",
    "rate_mechanic_point_5str_2 = rate_mechanic_point_5str_1.str[-3:]\n",
    "# rate_chatbot_point, rate_chatbot_pointについて、整数表記のため1文字分を抽出\n",
    "# rate_chatbot_point\n",
    "rate_chatbot_point_5str_1 = df_MH.loc[:, 'rate_chatbot_point'].str[-2:-1] \n",
    "rate_chatbot_point_5str_2 = rate_chatbot_point_5str_1.str[-1:]\n",
    "# rate_chatbot_agent_point\n",
    "rate_chatbot_agent_point_5str_1 = df_MH.loc[:, 'rate_chatbot_agent_point'].str[-5:-1] \n",
    "rate_chatbot_agent_point_5str_2 = rate_chatbot_agent_point_5str_1.str[-1:]\n",
    "\n",
    "\n",
    "### 文字列から数値への型変換\n",
    "# rate_service_point\n",
    "df_rate_service_point_num = pd.to_numeric(rate_service_point_5str_2, errors='coerce') \n",
    "# rate_mechanic_point\n",
    "df_rate_mechanic_point_num =  pd.to_numeric(rate_mechanic_point_5str_2, errors='coerce')\n",
    "# rate_chatbot_point\n",
    "df_rate_chatbot_point_num =  pd.to_numeric(rate_chatbot_point_5str_2, errors='coerce')\n",
    "# rate_chatbot_agent_point\n",
    "df_rate_chatbot_agent_point_num =  pd.to_numeric(rate_chatbot_agent_point_5str_2, errors='coerce')\n",
    "### dataframeへの変換\n",
    "df_rate_service_point_num = pd.DataFrame(df_rate_service_point_num)\n",
    "df_rate_mechanic_point_num =  pd.DataFrame(df_rate_mechanic_point_num)\n",
    "df_rate_chatbot_point_num =  pd.DataFrame(df_rate_chatbot_point_num)\n",
    "df_rate_chatbot_agent_point_num =  pd.DataFrame(df_rate_chatbot_agent_point_num)\n",
    "\n",
    "\n",
    "### - カラム名の変更とカラム抽出\n",
    "# - rate_service_point\n",
    "df_rate_service_point_num.rename(columns={\n",
    "    'rate_service_point' : 'rate_service_point_NUM'\n",
    "}, inplace=True)\n",
    "# - rate_mechanic_point\n",
    "df_rate_mechanic_point_num.rename(columns={\n",
    "    'rate_mechanic_point' : 'rate_mechanic_point_NUM'\n",
    "}, inplace=True)\n",
    "# - rate_chatbot_point\n",
    "df_rate_chatbot_point_num.rename(columns={\n",
    "    'rate_chatbot_point' : 'rate_chatbot_point_NUM'\n",
    "}, inplace=True)\n",
    "# - rate_chatbot_agent_point\n",
    "df_rate_chatbot_agent_point_num.rename(columns={\n",
    "    'rate_chatbot_agent_point': 'rate_chatbot_agent_point_NUM'\n",
    "}, inplace=True)\n",
    "### データの結合\n",
    "df_MH2 = pd.concat([df_MH, df_rate_service_point_num, df_rate_mechanic_point_num, df_rate_chatbot_point_num, df_rate_chatbot_agent_point_num], axis = 'columns')\n",
    "### 必要カラムの抽出\n",
    "df_MH2.drop(columns=['rate_service_point', 'rate_mechanic_point', 'rate_chatbot_point', 'rate_chatbot_agent_point'], inplace=True)\n",
    "# カラム名の編集\n",
    "df_MH2.rename(columns={\n",
    "    'rate_service_point_NUM' : 'rate_service_point',\n",
    "    'rate_mechanic_point_NUM' : 'rate_mechanic_point',\n",
    "    'rate_chatbot_point_NUM' : 'rate_chatbot_point',\n",
    "    'rate_chatbot_agent_point_NUM' : 'rate_chatbot_agent_point',\n",
    "}, inplace=True)\n",
    "# 必要カラムの抽出\n",
    "df_MH3 = df_MH2[['UID',  'rate_service_point', 'rate_mechanic_point', 'rate_chatbot_point', 'rate_chatbot_agent_point']]\n",
    "\n",
    "### uniqueなUIDごとに計算する\n",
    "# uniqueなUID（昇順）の取得\n",
    "df_uid = df_MH3['UID']\n",
    "uid_unique = df_uid.unique()\n",
    "df_uid_unique = pd.DataFrame({'UID': uid_unique})\n",
    "\n",
    "# UIDの出現回数をカウント\n",
    "df_uid_count = df_uid.value_counts().rename_axis('UID').reset_index(name='UID_counts_MyHonda')\n",
    "\n",
    "# uniqueなuid（昇順）に出現回数を付与\n",
    "df_uid_unique_count = pd.merge(df_uid_unique, df_uid_count, on='UID', how='left')\n",
    "\n",
    "# UIDごとに、各pointの平均をとる\n",
    "df_MyHonda = df_MH2.groupby(['UID'], dropna=False, as_index=False).agg(\n",
    "        rate_service_point = ('rate_service_point', 'mean'),\n",
    "        rate_mechanic_point = ('rate_mechanic_point', 'mean'),\n",
    "        rate_chatbot_point = ('rate_chatbot_point', 'mean'),\n",
    "        rate_chatbot_agent_point = ('rate_chatbot_agent_point', 'mean'),\n",
    ")\n",
    "# uniqueなUIDに結合\n",
    "df_MyHonda = pd.merge(df_uid_unique_count, df_MyHonda, on='UID', how='left')\n",
    "\n",
    "# MyhondaID有無を表すカラム：UIIDがあればMyHondaIDありとする\n",
    "# Check to see if MyHondaID exist or not, if UID exist then MyHondaID exist\n",
    "df_MyHonda.loc[:, [\"MyHonda有無\"]] = '1'\n",
    "\n",
    "### データの出力\n",
    "OUTPUT_PATH_MH = output_folder + \"/MH_new_name.csv\"\n",
    "df_MyHonda.to_csv(OUTPUT_PATH_MH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの入力\n",
    "INPUT_PATH_MH = input_tmp_folder + \"/MH.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_MH, encoding='utf-8')\n",
    "\n",
    "### カラムの抽出\n",
    "usecols = [\n",
    "    'rate_service_point',\n",
    "    'rate_mechanic_point',\n",
    "    'rate_chatbot_point',\n",
    "    'rate_chatbot_agent_point',\n",
    "    'UID',\n",
    "]\n",
    "\n",
    "df_MH = df[usecols]\n",
    "\n",
    "### 最後の点数を抽出\n",
    "# rate_service_point, rate_mechanic_pointについて、小数表記のため3文字分を抽出\n",
    "# rate_service_point\n",
    "rate_service_point_5str_1 = df_MH.loc[:, 'rate_service_point'].astype(str).str[:]\n",
    "rate_service_point_5str_2 = rate_service_point_5str_1.str[:]\n",
    "# rate_mechanic_point\n",
    "rate_mechanic_point_5str_1 = df_MH.loc[:, 'rate_mechanic_point'].astype(str).str[:]\n",
    "rate_mechanic_point_5str_2 = rate_mechanic_point_5str_1.str[:]\n",
    "# rate_chatbot_point, rate_chatbot_pointについて、整数表記のため1文字分を抽出\n",
    "# rate_chatbot_point\n",
    "rate_chatbot_point_5str_1 = df_MH.loc[:, 'rate_chatbot_point'].astype(str).str[:]\n",
    "rate_chatbot_point_5str_2 = rate_chatbot_point_5str_1.str[:]\n",
    "# # rate_chatbot_agent_point\n",
    "rate_chatbot_agent_point_5str_1 = df_MH.loc[:, 'rate_chatbot_agent_point'].astype(str).str[:]\n",
    "rate_chatbot_agent_point_5str_2 = rate_chatbot_agent_point_5str_1.str[:]\n",
    "\n",
    "\n",
    "### 文字列から数値への型変換\n",
    "# rate_service_point\n",
    "df_rate_service_point_num = pd.to_numeric(rate_service_point_5str_2, errors='coerce')\n",
    "# rate_mechanic_point\n",
    "df_rate_mechanic_point_num =  pd.to_numeric(rate_mechanic_point_5str_2, errors='coerce')\n",
    "# rate_chatbot_point\n",
    "df_rate_chatbot_point_num =  pd.to_numeric(rate_chatbot_point_5str_2, errors='coerce')\n",
    "# rate_chatbot_agent_point\n",
    "df_rate_chatbot_agent_point_num =  pd.to_numeric(rate_chatbot_agent_point_5str_2, errors='coerce')\n",
    "### dataframeへの変換\n",
    "\n",
    "df_rate_service_point_num = pd.DataFrame(df_rate_service_point_num)\n",
    "df_rate_mechanic_point_num =  pd.DataFrame(df_rate_mechanic_point_num)\n",
    "df_rate_chatbot_point_num =  pd.DataFrame(df_rate_chatbot_point_num)\n",
    "df_rate_chatbot_agent_point_num =  pd.DataFrame(df_rate_chatbot_agent_point_num)\n",
    "\n",
    "\n",
    "### - カラム名の変更とカラム抽出\n",
    "# - rate_service_point\n",
    "df_rate_service_point_num.rename(columns={\n",
    "    'rate_service_point' : 'rate_service_point_NUM'\n",
    "}, inplace=True)\n",
    "# - rate_mechanic_point\n",
    "df_rate_mechanic_point_num.rename(columns={\n",
    "    'rate_mechanic_point' : 'rate_mechanic_point_NUM'\n",
    "}, inplace=True)\n",
    "# - rate_chatbot_point\n",
    "df_rate_chatbot_point_num.rename(columns={\n",
    "    'rate_chatbot_point' : 'rate_chatbot_point_NUM'\n",
    "}, inplace=True)\n",
    "# # - rate_chatbot_agent_point\n",
    "df_rate_chatbot_agent_point_num.rename(columns={\n",
    "    'rate_chatbot_agent_point': 'rate_chatbot_agent_point_NUM'\n",
    "}, inplace=True)\n",
    "### データの結合\n",
    "#df_MH2 = pd.concat([df_MH, df_rate_service_point_num, df_rate_mechanic_point_num])#, df_rate_chatbot_point_num, df_rate_chatbot_agent_point_num], axis = 'columns')\n",
    "# df_MH2 = pd.concat([df_MH, df_rate_service_point_num, df_rate_mechanic_point_num], ignore_index=True)#, df_rate_chatbot_point_num, df_rate_chatbot_agent_point_num], axis = 'columns')\n",
    "df_MH2 = df_MH.copy()\n",
    "df_MH2['rate_service_point'] = df_rate_service_point_num['rate_service_point_NUM']\n",
    "df_MH2['rate_mechanic_point'] = df_rate_mechanic_point_num['rate_mechanic_point_NUM']\n",
    "df_MH2['rate_chatbot_point'] = df_rate_chatbot_point_num['rate_chatbot_point_NUM']\n",
    "df_MH2['rate_chatbot_agent_point'] = df_rate_chatbot_agent_point_num['rate_chatbot_agent_point_NUM']\n",
    "\n",
    "\n",
    "df_MH3 = df_MH2[['UID',  'rate_service_point', 'rate_mechanic_point','rate_chatbot_point', 'rate_chatbot_agent_point']]\n",
    "\n",
    "### uniqueなUIDごとに計算する\n",
    "# uniqueなUID（昇順）の取得\n",
    "df_uid = df_MH3['UID'].dropna()\n",
    "uid_unique = df_uid.unique()\n",
    "df_uid_unique = pd.DataFrame({'UID': uid_unique})\n",
    "\n",
    "# UIDの出現回数をカウント\n",
    "df_uid_count = df_uid.value_counts().rename_axis('UID').reset_index(name='UID_counts_MyHonda')\n",
    "\n",
    "# uniqueなuid（昇順）に出現回数を付与\n",
    "df_uid_unique_count = pd.merge(df_uid_unique, df_uid_count, on='UID', how='left')\n",
    "# UIDごとに、各pointの平均をとる\n",
    "\n",
    "grouped_service_point = df_MH2.groupby(['UID'])['rate_service_point'].mean().reset_index()\n",
    "grouped_mechanic_point = df_MH2.groupby(['UID'])['rate_mechanic_point'].mean().reset_index()\n",
    "grouped_chatbot_point = df_MH2.groupby(['UID'])['rate_chatbot_point'].mean().reset_index()\n",
    "grouped_agent_point = df_MH2.groupby(['UID'])['rate_chatbot_agent_point'].mean().reset_index()\n",
    "\n",
    "df_MyHonda = pd.merge(grouped_service_point, grouped_mechanic_point, on='UID', how='left')\n",
    "df_MyHonda = pd.merge(df_MyHonda, grouped_chatbot_point, on='UID', how='left')\n",
    "df_MyHonda = pd.merge(df_MyHonda, grouped_agent_point, on='UID', how='left')\n",
    "\n",
    "df_MyHonda = pd.merge(df_uid_unique_count, df_MyHonda, on='UID', how='left')\n",
    "df_MyHonda.drop_duplicates(subset='UID', inplace=True)\n",
    "\n",
    "# MyhondaID有無を表すカラム：UIIDがあればMyHondaIDありとする\n",
    "# Check to see if MyHondaID exist or not, if UID exist then MyHondaID exist\n",
    "df_MyHonda.loc[:, [\"MyHonda有無\"]] = '1'\n",
    "\n",
    "### データの出力\n",
    "OUTPUT_PATH_MH = output_folder + \"/MH_new_name.csv\"\n",
    "df_MyHonda.to_csv(OUTPUT_PATH_MH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# booking_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UIDから出現回数と有無を表すフラグを立てる関数\n",
    "def uid_unique_count_flag(df, filename):\n",
    "    # df_uid: UIDのみのタプル\n",
    "    df_uid = df['UID']\n",
    "\n",
    "    # uniqueなUIDの取得\n",
    "    uid_unique = df_uid.unique()\n",
    "    df_uid_unique = pd.DataFrame({'UID': uid_unique})\n",
    "    \n",
    "    # UIDの出現回数\n",
    "    column_name = 'UID_counts_' + filename\n",
    "    df_uid_count = df_uid.value_counts().rename_axis('UID').reset_index(name=column_name)\n",
    "    \n",
    "    # uniqueなuidと出現回数のカラムの結合\n",
    "    df_uid_unique_count = pd.merge(df_uid_unique, df_uid_count, on='UID', how='left')\n",
    "    \n",
    "    # UID有無を表すカラム\n",
    "    df_uid_unique_count.loc[:, [\"UID有無\"]] = '1'\n",
    "\n",
    "    return df_uid_unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24408\\4402498.py:4: DtypeWarning: Columns (3,10,12,14,16,22,24,26,27,28,29,30,31,32,38,39,40,41,42,44,47,51,52,53,55,57,58,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(INPUT_PATH_BOOK, encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "### データの入力\n",
    "# BOOK data's field has a space before most columns\n",
    "INPUT_PATH_BOOK = input_tmp_folder + \"/book.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_BOOK, encoding='utf-8')\n",
    "#df_book = df.iloc[:, [-1, 1, 3, 5, 13]]\n",
    "df_book = df[['UID', 'dealer_code', 'job_service_type', 'emp_id', 'booking_date']]\n",
    "\n",
    "df_book_uid = uid_unique_count_flag(df_book, 'book')\n",
    "\n",
    "### emp_idについての処理\n",
    "df_book[\"emp_id_num\"] = pd.to_numeric(df_book['emp_id'], errors='coerce') # <==== emp_id has a space before it\n",
    "df_book.loc[~df_book['emp_id_num'].isna(), ['emp_choice']] = 1\n",
    "df_book.loc[df_book['emp_id_num'].isna(), ['emp_choice']] = 0\n",
    "df_emp = df_book.groupby(by='UID').agg(\n",
    "    emp_id_count=('emp_choice', 'sum'),\n",
    "    emp_id_有無=('emp_choice', 'max'),\n",
    ").reset_index()\n",
    "\n",
    "### booking_dateについての処理\n",
    "df_booking_date = df_book.groupby(by=\"UID\").aggregate(\n",
    "    booking_date_count = ('booking_date', 'nunique'), # <==== booking_date has a space before it\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "### 結合\n",
    "df_book_uid = pd.merge(df_book_uid, df_emp, on = 'UID', how='left')\n",
    "df_book_uid = pd.merge(df_book_uid, df_booking_date, on = 'UID', how='left')\n",
    "\n",
    "### データの出力\n",
    "OUTPUT_PATH_book = output_folder + \"/book_new_name.csv\"\n",
    "df_book_uid.to_csv(OUTPUT_PATH_book, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notificiation_tracking, event_tracking\n",
    "- 処理ファイル一覧\n",
    "    - event_v_promo.csv\n",
    "    - notif_vpi\n",
    "    - notif_vpm\n",
    "    - notif_v_pro\n",
    "    - notif_v_spa\n",
    "    - notif_book_pi\n",
    "    - notif_book_pm\n",
    "    - notif_book_spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UIDから出現回数と有無を表すフラグを立てる関数\n",
    "def uid_unique_count_flag(df, filename):\n",
    "    # df_uid: UIDのタプル\n",
    "    df_uid = df['UID']\n",
    "\n",
    "    # uniqueなUIDの取得\n",
    "    uid_unique = df_uid.unique()\n",
    "    df_uid_unique = pd.DataFrame({'UID': uid_unique})\n",
    "\n",
    "    # UIDの出現回数をカウント\n",
    "    column_name = 'UID_counts'\n",
    "    df_uid_count = df_uid.value_counts().rename_axis('UID').reset_index(name=column_name)\n",
    "    \n",
    "    # uniqueなuidと出現回数のカラムの結合\n",
    "    df_uid_unique_count = pd.merge(df_uid_unique, df_uid_count, on='UID', how='left')\n",
    "    \n",
    "\n",
    "    # UID有無を表すカラム\n",
    "    df_uid_unique_count[filename] = '1'\n",
    "\n",
    "    if filename == \"event_v_promo\":\n",
    "        # event_v_promoの場合\n",
    "        #   UID有無を表すカラムのカラム名をcoupon_useに変更\n",
    "        df_uid_unique_count = df_uid_unique_count.rename(columns={filename: \"coupon_use\"})\n",
    "        #   UIDの出現回数を表すカラムのカラム名をevent_v_promoに変更\n",
    "        df_uid_unique_count = df_uid_unique_count.rename(columns={\"UID_counts\": filename})\n",
    "\n",
    "    elif filename == \"notif_v_pro\":\n",
    "        # notif_v_proの場合\n",
    "        #   UID有無を表すカラムを削除\n",
    "        df_uid_unique_count = df_uid_unique_count.drop(columns=filename, errors='ignore')\n",
    "        #   UIDの出現回数を表すカラムのカラム名をevent_v_promoに変更\n",
    "        df_uid_unique_count = df_uid_unique_count.rename(columns={\"UID_counts\": \"coupon_view\"})\n",
    "\n",
    "    else:\n",
    "        # その他の場合\n",
    "        #   UIDの出現回数を表すカラムを削除\n",
    "        df_uid_unique_count = df_uid_unique_count.drop(columns=\"UID_counts\")\n",
    "\n",
    "    return df_uid_unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 入力パス、出力パスの指定\n",
    "PATH_DIR = input_tmp_folder\n",
    "OUTPUT_PATH_DIR = output_folder\n",
    "\n",
    "input_filename_list = [\n",
    "    \"event_v_promo\", #  view_promotion_notification\n",
    "    \"notif_vpi\", # view_pi_remind_notification\n",
    "    \"notif_vpm\", # view_pm_remind_notification\n",
    "    \"notif_v_pro\", # view_promotion_notification\n",
    "    \"notif_v_spa\", # view_sparepart_notification\n",
    "    \"notif_book_pi\", # booking_pi_remind_notification\n",
    "    \"notif_book_pm\", # booking_pm_service\n",
    "    \"notif_book_spa\", # booking_sparepart\n",
    "]\n",
    "\n",
    "input_path_list = []\n",
    "output_path_list = []\n",
    "\n",
    "for name in input_filename_list:\n",
    "    # input\n",
    "    name_csv = name + '.csv'\n",
    "    input_path = os.path.join(PATH_DIR, name_csv)\n",
    "    input_path_list.append(input_path)\n",
    "\n",
    "    # output\n",
    "    output_name = name_csv.replace(\".csv\", \"_new_name.csv\")\n",
    "    output_path = os.path.join(OUTPUT_PATH_DIR, output_name)\n",
    "    output_path_list.append(output_path)\n",
    "\n",
    "### 各ファイルについて処理\n",
    "for input, output, filename in zip(input_path_list, output_path_list, input_filename_list):\n",
    "    df_input = pd.read_csv(input, encoding=\"utf-8\")\n",
    "    df_output = uid_unique_count_flag(df_input, filename)\n",
    "    df_output.to_csv(output, encoding=\"utf-8\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### notif_v_pro, event_v_promoについて、個別に対応\n",
    "df_notif = \"↑のセルで生成したファイルのパスを個別に指定\"\n",
    "df_event = \"↑のセルで生成したファイルのパスを個別に指定\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの入力\n",
    "INPUT_PATH_SCA = input_tmp_folder + \"/SCA.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_SCA, encoding='utf-8')\n",
    "df['start_date_df'] = pd.to_datetime(df['start_date'])\n",
    "\n",
    "### カラムの抽出\n",
    "df_sca_input = df[['UID', 'start_date_df']]\n",
    "\n",
    "### UIDごと\n",
    "df_sca = df_sca_input.groupby(by='UID').agg(\n",
    "    sca_visit_num=('start_date_df', 'count'),\n",
    ").reset_index()\n",
    "\n",
    "### 出力\n",
    "OUTPUT_PATH_SCA = output_folder + \"/SCA_output.csv\"\n",
    "df_sca.to_csv(OUTPUT_PATH_SCA, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの入力\n",
    "INPUT_PATH_COMP = input_tmp_folder + \"/comp.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_COMP, encoding='utf-8')\n",
    "#df['start_date_df'] = pd.to_datetime(df['start_date'])\n",
    "df['start_date_df'] = pd.to_datetime(df['Date/Time Opened'])\n",
    "\n",
    "\n",
    "### カラムの抽出\n",
    "df_comp_input = df.loc[:, ['UID', 'CR Code Full']]\n",
    "df_comp_input['suggestion'] = 0\n",
    "\n",
    "\n",
    "# CR code full（提案）に属するフラグを立てる\n",
    "list_suggestion = [\"CA99\", \" CB98\", \" CB99\", \" CC99\", \" CD99\", \" CE99\", \" CF99\", \" CZ99\", \" CZ80\", \" CZ81\"]\n",
    "df_comp_input.loc[df_comp_input[\"CR Code Full\"].isin(list_suggestion), ['suggestion']] = 1 \n",
    "\n",
    "\n",
    "### UIDごとの提案回数をカウント\n",
    "df_comp = df_comp_input.groupby(by='UID').agg(\n",
    "    CR_feedback=('suggestion', 'count'),\n",
    ").reset_index()\n",
    "df_comp['CR'] = '1'\n",
    "\n",
    "### 出力\n",
    "OUTPUT_PATH_COMP = output_folder + \"/comp_output.csv\"\n",
    "df_comp.to_csv(OUTPUT_PATH_COMP, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの入力\n",
    "INPUT_PATH_EW = input_tmp_folder + \"/ew.csv\"\n",
    "df = pd.read_csv(INPUT_PATH_EW, encoding='utf-8')\n",
    "#df['start_date_df'] = pd.to_datetime(df['start_date'])\n",
    "df['start_date_df'] = pd.to_datetime(df['EW START '])\n",
    "\n",
    "### カラムの抽出・カラム名の修正\n",
    "df_ew = df.copy()\n",
    "# カラム名の修正\n",
    "df_ew.rename(columns={\n",
    "    'Lo<U+1EA1>i goi' : 'Package_Type',\n",
    "    'Loại gói' : 'Package_Type',\n",
    "}, inplace=True)\n",
    "df_ew = df_ew[['start_date_df', 'Package_Type', 'NET', 'UID']]\n",
    "\n",
    "\n",
    "### UIDごとの算出\n",
    "df_ew_NewTotal = df_ew.groupby(by='UID').agg(\n",
    "    ew_sales=('NET', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "### ALL_carフラグを立てて算出\n",
    "df_ew['ALL_car'] = 0\n",
    "df_ew.loc[df_ew[\"Package_Type\"]=='All car', ['ALL_car']] = 1 \n",
    "df_ew_Allcar = df_ew.groupby(by='UID').agg(\n",
    "    ew_all_car = ('ALL_car', 'max'),\n",
    "    ew_nun = ('ALL_car', 'sum')\n",
    ")\n",
    "\n",
    "### 結合\n",
    "df_ew_output = pd.merge(df_ew_NewTotal, df_ew_Allcar, on='UID', how = 'outer')\n",
    "\n",
    "### 出力\n",
    "OUTPUT_PATH = output_folder + \"/ew_output.csv\"\n",
    "df_ew_output.to_csv(OUTPUT_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの入力\n",
    "INPUT_PATH = input_tmp_folder + \"/chat.csv\"\n",
    "#collist = [10, 5, 6]\n",
    "\n",
    "collist = ['UID', 'Business', 'Field']\n",
    "df = pd.read_csv(INPUT_PATH, usecols=collist, encoding='utf-8')\n",
    "\n",
    "### UIDの出現回数のカウント\n",
    "df_uid_count = df['UID'].value_counts().rename_axis('UID').reset_index(name='chat_num')\n",
    "\n",
    "### Service Partについて\n",
    "# Business=AMかつField=Servideのレコードにフラグ1、その他を0として→agg max\n",
    "df.loc[(df['Business'] == 'AM') & (df['Field'] == 'Service'), ['Business_Field']] = 1\n",
    "df.loc[~((df['Business'] == 'AM') & (df['Field'] == 'Service')), ['Business_Field']] = 0\n",
    "df_service_part = df.groupby(by='UID').agg(\n",
    "    service_part = ('Business_Field', 'max')\n",
    ").reset_index()\n",
    "\n",
    "### 結合\n",
    "df_chat = pd.merge(df_uid_count, df_service_part, on = 'UID', how='left')\n",
    "\n",
    "# UID有無を表す列を作成\n",
    "\n",
    "#df_chat.loc[:, 'chat'] = 1\n",
    "df_chat['chat'] = 1\n",
    "\n",
    "\n",
    "# 必要カラムの抽出\n",
    "df_chat_output = df_chat[['UID', 'chat','chat_num' , 'service_part']]\n",
    "\n",
    "# データの出力\n",
    "OUTPUT_PATH = output_folder + \"/chat_output.csv\"\n",
    "df_chat.to_csv(OUTPUT_PATH, index=False, encoding=False)\n",
    "\n",
    "# test_drive\n",
    "#PATH_DIR = \"C:/Users/J0135690/OneDrive - Honda/ドキュメント/プロジェクト/CeDX/データ\"\n",
    "#INPUT_PATH = os.path.join(PATH_DIR, \"test_drive.csv\")\n",
    "#OUTPUT_PATH = os.path.join(PATH_DIR, \"test_drive_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの入力\n",
    "INPUT_PATH = input_tmp_folder + \"/test_drive.csv\"\n",
    "df = pd.read_csv(INPUT_PATH, encoding='utf-8')\n",
    "\n",
    "# UIDごとにevent_date回数をカウント\n",
    "df_test_drive = df.groupby(by='UID').agg(\n",
    "    test_drive = ('event_date', 'count')\n",
    ").reset_index()\n",
    "\n",
    "### データの出力\n",
    "OUTPUT_PATH = output_folder + \"/test_drive_output.csv\"\n",
    "df_test_drive.to_csv(OUTPUT_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view_test_drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### データの入力\n",
    "INPUT_PATH = input_tmp_folder + \"/view_test_drive.csv\"\n",
    "df = pd.read_csv(INPUT_PATH, encoding='utf-8')\n",
    "\n",
    "# UIDごとにevent_date回数をカウント\n",
    "df_view_test_drive = df.groupby(by='UID').agg(\n",
    "    view_test_drive=('event_date', 'count')\n",
    ").reset_index()\n",
    "\n",
    "### データの出力\n",
    "OUTPUT_PATH = output_folder + \"/view_test_drive_output.csv\"\n",
    "df_view_test_drive.to_csv(OUTPUT_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view_promotion_notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの入力\n",
    "INPUT_PATH = input_tmp_folder + \"/view_promotion_notification.csv\"\n",
    "df = pd.read_csv(INPUT_PATH, encoding='utf-8')\n",
    "\n",
    "# UIDごとにevent_date回数をカウント\n",
    "df_view_promotion_notification = df.groupby(by='UID').agg(\n",
    "    view_promotion_notification=('event_date', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# データの出力\n",
    "OUTPUT_PATH = output_folder + \"/view_promotion_notification_output.csv\"\n",
    "df_view_promotion_notification.to_csv(OUTPUT_PATH, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare_product, estimate_cost, view_productについて\n",
    "\n",
    "- 入力したファイル一覧\n",
    "    - compare_product,\n",
    "    - estimate_cost,\n",
    "    - view_product_detail_am,\n",
    "    - view_product_gallery,\n",
    "    - view_product_list,\n",
    "    - view_product_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yymmdd_count(df, s):\n",
    "    df_output = df.groupby(by='UID').agg(\n",
    "        s = ('event_date', 'count')\n",
    "    ).reset_index()\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AO_HVN_ITS_LABO_DWH\\AppData\\Local\\Temp\\ipykernel_24408\\4286193358.py:30: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_input = pd.read_csv(input, encoding=\"utf-8\")\n"
     ]
    }
   ],
   "source": [
    "### 入力パス、出力パスの指定\n",
    "PATH_DIR = input_tmp_folder\n",
    "OUTPUT_PATH_DIR = output_folder\n",
    "\n",
    "INPUT_FILENAME_LIST = [\n",
    "    'compare_product_am',\n",
    "    'estimate_cost',\n",
    "    'view_product_detail_am',\n",
    "    'view_product_gallery',\n",
    "    'view_product_list',\n",
    "    'view_product_color'\n",
    "]\n",
    "\n",
    "input_path_list = []\n",
    "output_path_list = []\n",
    "\n",
    "for name in INPUT_FILENAME_LIST:\n",
    "    # input\n",
    "    name_csv = name + '.csv'\n",
    "    input_path = os.path.join(PATH_DIR, name_csv)\n",
    "    input_path_list.append(input_path)\n",
    "\n",
    "    # output\n",
    "    output_name_csv = name_csv.replace(\".csv\", \"_output.csv\")\n",
    "    output_path = os.path.join(OUTPUT_PATH_DIR, output_name_csv)\n",
    "    output_path_list.append(output_path)\n",
    "\n",
    "### 各ファイルについて処理\n",
    "for input, output, filename in zip(input_path_list, output_path_list, INPUT_FILENAME_LIST):\n",
    "    df_input = pd.read_csv(input, encoding=\"utf-8\")\n",
    "    df_output = yymmdd_count(df_input, filename)\n",
    "    df_output.to_csv(output, encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change columns name of some files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names in file book_new_name.csv\n",
    "book_new_name_cols = {'UID': 'UID',\n",
    "'UID_counts_book': 'UID_counts_book',\n",
    "'UID有無': 'UID有無',\n",
    "'emp_id_count': 'app_mente_SA_select',\n",
    "'emp_id_有無': 'SA_select',\n",
    "'booking_date_count': 'app_reserve_mean'}\n",
    "\n",
    "\n",
    "book_new_name_file = output_folder + \"/book_new_name.csv\"\n",
    "pd.read_csv(book_new_name_file, encoding='utf-8').rename(columns=book_new_name_cols, errors='ignore').to_csv(book_new_name_file, index=False)\n",
    "                                                                  \n",
    "# Change column names in file DCSI_output_ver2.csv\n",
    "DCSI_output_ver2_cols ={'UID': 'UID',\n",
    "'Month': 'Month',\n",
    "'Year': 'Year',\n",
    "'Dealer': 'Dealer',\n",
    "'Region': 'Region',\n",
    "'REMINDER_': 'satisfaction_reminder',\n",
    "'RECEPTION': 'satisfaction_reception',\n",
    "'CUSTOMER_LOUNGE': 'satisfaction_customer_lounge',\n",
    "'DELIVERY': 'satisfaction_delivery',\n",
    "'REPAIR_QUALITY': 'satisfaction_repair_quality',\n",
    "'FACILITY': 'satisfaction_facility',\n",
    "'Q30Y': 'one_time_repair',\n",
    "'OVERALL_SATISFACTION': 'total_satisfaction',\n",
    "'Free_comment': 'Free_comment',\n",
    "'follow_call': 'follow_call'}\n",
    "\n",
    "\n",
    "\n",
    "DCSI_output_ver2_file = output_folder + \"/DCSI_output_ver2.csv\"\n",
    "pd.read_csv(DCSI_output_ver2_file, encoding='utf-8').rename(columns=DCSI_output_ver2_cols, errors='ignore').to_csv(DCSI_output_ver2_file, index=False)\n",
    "         \n",
    "# Change column names in file ew_output.csv\n",
    "ew_output_cols = {'UID': 'UID',\n",
    "'ew_sales': 'ew_sales',\n",
    "'ew_all_car': 'ew_all_car',\n",
    "'ew_nun': 'ew_num'}\n",
    "\n",
    "ew_output_file = output_folder + \"/ew_output.csv\"\n",
    "pd.read_csv(ew_output_file, encoding='utf-8').rename(columns=ew_output_cols, errors='ignore').to_csv(ew_output_file, index=False)\n",
    "\n",
    "# Change column names in file MH_new_name.csv\n",
    "MH_new_name_cols ={'UID': 'UID',\n",
    "'UID_counts_MyHonda': 'MH_Active',\n",
    "'rate_service_point': 'satisfaction_service',\n",
    "'rate_mechanic_point': 'satisfaction_mechanic',\n",
    "'rate_chatbot_point': 'satisfaction_chatbot',\n",
    "'rate_chatbot_agent_point': 'satisfaction_chatbot_agent',\n",
    "'MyHonda有無': 'MH_ID'}\n",
    "MH_new_name_file = output_folder + \"/MH_new_name.csv\"\n",
    "pd.read_csv(MH_new_name_file, encoding='utf-8').rename(columns=MH_new_name_cols, errors='ignore').to_csv(MH_new_name_file, index=False)\n",
    "\n",
    "\n",
    "# Drop redundant column in file sale_uni_min.csv\n",
    "#sale_uni_min_file = root_folder + \"/data/input/sale_uni_min.csv\"\n",
    "#pd.read_csv(sale_uni_min_file, encoding='utf-8').drop('Unnamed: 0', errors='ignore').to_csv(sale_uni_min_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
